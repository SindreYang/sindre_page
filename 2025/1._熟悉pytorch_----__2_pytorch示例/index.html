<!DOCTYPE html>
<html lang="zh-CN,en,default">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 7.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">
  <link rel="stylesheet" href="/lib/pace/pace-theme-minimal.min.css">
  <script src="/lib/pace/pace.min.js"></script>

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"blog.mviai.com","root":"/","scheme":"Gemini","version":"7.8.0","exturl":true,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":true,"style":"mac"},"back2top":{"enable":true,"sidebar":false,"scrollpercent":true},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":true,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="自动摘要: 官网：[https:&#x2F;&#x2F;pytorch.org&#x2F;tutorials&#x2F;beginner&#x2F;pytorch_with_examples.html](https:&#x2F;&#x2F;pytorch.org&#x2F;tutorials ……..">
<meta property="og:type" content="article">
<meta property="og:title" content="1">
<meta property="og:url" content="http://blog.mviai.com/2025/1._%E7%86%9F%E6%82%89pytorch_----__2_pytorch%E7%A4%BA%E4%BE%8B/index.html">
<meta property="og:site_name" content="落叶无痕">
<meta property="og:description" content="自动摘要: 官网：[https:&#x2F;&#x2F;pytorch.org&#x2F;tutorials&#x2F;beginner&#x2F;pytorch_with_examples.html](https:&#x2F;&#x2F;pytorch.org&#x2F;tutorials ……..">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2025-01-22T04:37:41.000Z">
<meta property="article:modified_time" content="2025-01-22T12:37:41.567Z">
<meta property="article:author" content="SindreYang">
<meta property="article:tag" content="生活">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://blog.mviai.com/2025/1._%E7%86%9F%E6%82%89pytorch_----__2_pytorch%E7%A4%BA%E4%BE%8B/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>1 | 落叶无痕</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">落叶无痕</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>首页</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-fw fa-user"></i>关于</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i>分类<span class="badge">72</span></a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>归档<span class="badge">321</span></a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>

  <span class="exturl github-corner" data-url="aHR0cHM6Ly9naXRodWIuY29tL1NpbmRyZVlhbmc=" title="Follow me on GitHub" aria-label="Follow me on GitHub"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></span>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://blog.mviai.com/2025/1._%E7%86%9F%E6%82%89pytorch_----__2_pytorch%E7%A4%BA%E4%BE%8B/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="SindreYang">
      <meta itemprop="description" content="沉淀后我愿意做一个温暖的人。有自己的喜好，有自己的原则，有自己的信仰，不急功近利，不浮夸轻薄，宠辱不惊，淡定安逸，心静如水。------不忘初心，方得始终">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="落叶无痕">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          1
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2025-01-22 12:37:41 / 修改时间：20:37:41" itemprop="dateCreated datePublished" datetime="2025-01-22T12:37:41+08:00">2025-01-22</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%88%86%E5%89%B2%E5%9F%B9%E8%AE%AD%E8%AE%A1%E5%88%92/" itemprop="url" rel="index"><span itemprop="name">分割培训计划</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="fa fa-comment-o"></i>
      </span>
      <span class="post-meta-item-text">Changyan：</span>
    
    
      <a title="changyan" href="/2025/1._%E7%86%9F%E6%82%89pytorch_----__2_pytorch%E7%A4%BA%E4%BE%8B/#SOHUCS" itemprop="discussionUrl">
        <span id="changyan_count_unit" class="post-comments-count hc-comment-count" data-xid="2025/1._熟悉pytorch_----__2_pytorch示例/" itemprop="commentCount"></span>
      </a>
    
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>自动摘要: 官网：[<span class="exturl" data-url="aHR0cHM6Ly9weXRvcmNoLm9yZy90dXRvcmlhbHMvYmVnaW5uZXIvcHl0b3JjaF93aXRoX2V4YW1wbGVzLmh0bWxd" title="https://pytorch.org/tutorials/beginner/pytorch_with_examples.html]">https://pytorch.org/tutorials/beginner/pytorch_with_examples.html]<i class="fa fa-external-link"></i></span>(<span class="exturl" data-url="aHR0cHM6Ly9weXRvcmNoLm9yZy90dXRvcmlhbHM=" title="https://pytorch.org/tutorials">https://pytorch.org/tutorials<i class="fa fa-external-link"></i></span> ……..</p>
<span id="more"></span>
<p>官网：<span class="exturl" data-url="aHR0cHM6Ly9weXRvcmNoLm9yZy90dXRvcmlhbHMvYmVnaW5uZXIvcHl0b3JjaF93aXRoX2V4YW1wbGVzLmh0bWw=" title="https://pytorch.org/tutorials/beginner/pytorch_with_examples.html">https://pytorch.org/tutorials/beginner/pytorch_with_examples.html<i class="fa fa-external-link"></i></span>中文官网：<span class="exturl" data-url="aHR0cHM6Ly9weXRvcmNoLmFwYWNoZWNuLm9yZy8jL2RvY3MvMS43LzA3" title="https://pytorch.apachecn.org/#/docs/1.7/07">https://pytorch.apachecn.org/#/docs/1.7/07<i class="fa fa-external-link"></i></span>网友示例网址：网站：<span class="exturl" data-url="aHR0cHM6Ly9zby5jc2RuLm5ldC9zby9zZWFyY2g/cT1weXRvcmNoJnNwbT0xMDAxLjIxMDEuMzAwMS43MDIw" title="https://so.csdn.net/so/search?q=pytorch&spm=1001.2101.3001.7020">https://so.csdn.net/so/search?q=pytorch&spm=1001.2101.3001.7020<i class="fa fa-external-link"></i></span></p>
<p>将用一个三阶多项式拟合 y &#x3D; sin (x)的问题作为运行示例。该网络将有四个参数，并将使用梯度下降进行训练，以通过最小化网络输出和真实输出之间的欧几里得距离来拟合随机数据。</p>
<h1 id="Tensors"><a href="#Tensors" class="headerlink" title="Tensors"></a>Tensors</h1><h2 id="Warm-up-numpy"><a href="#Warm-up-numpy" class="headerlink" title="Warm-up: numpy"></a>Warm-up: numpy</h2><p>用Numpy 构建网络。Numpy 提供了一个 n 维数组对象，以及许多用于操作数组的函数。Numpy是科学计算的通用框架，它对计算图、深度学习或梯度一无所知，但是却可以很容易地使用numpy将三阶多项式拟合到正弦函数，方法是使用numpy运算手动实现网络中的正向和反向传递：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import math</span><br><span class="line"></span><br><span class="line">#create random input and output data</span><br><span class="line">x = np.linspace(-math.pi,math.pi,2000)</span><br><span class="line">y = np.sin(x)</span><br><span class="line"></span><br><span class="line">#Randomly initialize weights：将每个参数都初始化为某一个闭区间内的随机数</span><br><span class="line">a = np.random.randn()</span><br><span class="line">b = np.random.randn()</span><br><span class="line">c = np.random.randn()</span><br><span class="line">d = np.random.randn()</span><br><span class="line"></span><br><span class="line">learning_rate = 1e-6    #1e-6实际上就是科学计数法,1乘以10的-6次方</span><br><span class="line">for t in range(2000):</span><br><span class="line">    #forward pass: compute predicted y</span><br><span class="line">    y_pred = a + b * x + c + x **2 +d * x ** 3</span><br><span class="line"></span><br><span class="line">    #compute and print loss</span><br><span class="line">    loss = np.square(y_pred - y).sum()</span><br><span class="line">    if t % 100 == 99:</span><br><span class="line">        print(t,loss)</span><br><span class="line"></span><br><span class="line">    #backprop tp compute gradients of a, b, c, d with respect to loss</span><br><span class="line">    grad_y_pred = 2.0 * (y_pred - y)</span><br><span class="line">    grad_a = grad_y_pred.sum()</span><br><span class="line">    grad_b = (grad_y_pred*x).sum()</span><br><span class="line">    grad_c = (grad_y_pred*x**2).sum()</span><br><span class="line">    grad_d = (grad_y_pred*x**3).sum()</span><br><span class="line"></span><br><span class="line">    #update weights</span><br><span class="line">    a -= learning_rate * grad_a</span><br><span class="line">    b -= learning_rate * grad_b</span><br><span class="line">    c -= learning_rate * grad_c</span><br><span class="line">    d -= learning_rate * grad_d</span><br><span class="line"></span><br><span class="line">print(f&quot;result: y = &#123;a&#125; + &#123;b&#125; x +&#123;c&#125; x^2 + &#123;d&#125; x^3&quot;)</span><br></pre></td></tr></table></figure>
<p>输出结果：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">99 19478.36912480685</span><br><span class="line">199 24419.251261778834</span><br><span class="line">299 25574.360965011576</span><br><span class="line">399 25705.06579423957</span><br><span class="line">499 25671.37758666033</span><br><span class="line">599 25627.59865465535</span><br><span class="line">699 25594.83808699323</span><br><span class="line">799 25572.500606645255</span><br><span class="line">899 25557.61060307196</span><br><span class="line">999 25547.74346998343</span><br><span class="line">1099 25541.21508840787</span><br><span class="line">1199 25536.89753185557</span><br><span class="line">1299 25534.042428319648</span><br><span class="line">1399 25532.154468842375</span><br><span class="line">1499 25530.906050928475</span><br><span class="line">1599 25530.080533239998</span><br><span class="line">1699 25529.53465909364</span><br><span class="line">1799 25529.173699489627</span><br><span class="line">1899 25528.935014746876</span><br><span class="line">1999 25528.77718432666</span><br><span class="line">result: y = 14.593544901681053 + 0.8396782996625627 x +-19.907573693869118 x^2 + -0.09090339082228781 x^3</span><br></pre></td></tr></table></figure>
<p>其中：numpy.random.randn()和numpy.random.randn(d0,d1,…,dn)：</p>
<ul>
<li>rand函数根据给定维度生成[0,1)之间的一个或一组样本，包含0，不包含1；</li>
<li>randn函数返回一个或一组样本；</li>
<li>dn表格每个维度；</li>
<li>返回值为指定维度的array；</li>
<li>np.random.randn() # 当没有参数时，返回单个数据。</li>
</ul>
<p>numpy.linspace()：序列生成器，函数用于在线性空间中以均匀步长生成数字序列。numpy.linspace(start, stop, num&#x3D;50, endpoint&#x3D;True, retstep&#x3D;False, dtype&#x3D;None)生成一个指定大小，指定数据区间的均匀分布序列，参数介绍：</p>
<ul>
<li>start：序列中数据的下界。</li>
<li>end：序列中数据的上界。</li>
<li>num：生成序列包含num个元素；其值默认为50。</li>
<li>endpoint：取True时，序列包含最大值end；否则不包含；其值默认为True。</li>
<li>retstep：该值取True时，生成的序列中显示间距；反正不显示；其值默认为false。</li>
<li>dtype：数据类型，可以指定生成序列的数据类型；当为None时，根据其他输入推断数据类型。</li>
<li>返回值：是一个数组。</li>
</ul>
<h2 id="Pytorch-Tensors"><a href="#Pytorch-Tensors" class="headerlink" title="Pytorch:Tensors"></a>Pytorch:Tensors</h2><p>Numpy是一个很棒的框架，但它不能利用GPU来加速其数值计算。对于现代深度神经网络，GPU通常提供50倍或更高的加速，因此不幸的是，numpy对于现代深度学习来说还不够。在这里，我们介绍最基本的PyTorch概念：张量。PyTorch张量在概念上与numpy数组相同：张量是n维数组，PyTorch提供了许多函数来操作这些张量。在幕后，张量可以跟踪计算图形和梯度，但它们作为科学计算的通用工具也很有用。与numpy不同，PyTorch张量可以利用GPU来加速其数字计算。要在GPU上运行PyTorch张量，只需指定正确的设备即可。在这里，使用PyTorch张量将三阶多项式拟合到正弦函数。就像上面的numpy示例一样，需要手动实现通过网络的向前和向后传递：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line">import math</span><br><span class="line"></span><br><span class="line">dtype = torch.float</span><br><span class="line">device = torch.device(&quot;cpu&quot;)</span><br><span class="line">#device = torch.device(&quot;cuda:0&quot;) #uncomment this to run GPU</span><br><span class="line"></span><br><span class="line">#create random input and output data</span><br><span class="line">x = torch.linspace(-math.pi, math.pi, 2000, device=device, dtype=dtype)</span><br><span class="line">y = torch.sin(x)</span><br><span class="line"></span><br><span class="line">#randomly initialize weights</span><br><span class="line">a = torch.randn((),device=device,dtype=dtype)</span><br><span class="line">b = torch.randn((),device=device,dtype=dtype)</span><br><span class="line">c = torch.randn((),device=device,dtype=dtype)</span><br><span class="line">d = torch.randn((),device=device,dtype=dtype)</span><br><span class="line"></span><br><span class="line">learning_rate = 1e-6</span><br><span class="line">for t in range(2000):</span><br><span class="line">    #forward pass: compute predicted y</span><br><span class="line">    y_pred = a + b * x +c * x ** 2 + d * x ** 3</span><br><span class="line"></span><br><span class="line">    #compute and print loss</span><br><span class="line">    loss = (y_pred - y).pow(2).sum().item()    #item()取出单元素张量的元素值并返回该值</span><br><span class="line">    if t % 100 == 99:</span><br><span class="line">        print(t, loss)</span><br><span class="line"></span><br><span class="line">    #backprop to compute gradients of a, b, c, d with respect to loss</span><br><span class="line">    grad_y_pred = 2.0 * (y_pred - y)</span><br><span class="line">    grad_a = grad_y_pred.sum()</span><br><span class="line">    grad_b = (grad_y_pred * x).sum()</span><br><span class="line">    grad_c = (grad_y_pred * x ** 2).sum()</span><br><span class="line">    grad_d = (grad_y_pred * x ** 3).sum()</span><br><span class="line"></span><br><span class="line">    #update weight using gradient descent</span><br><span class="line">    a -= learning_rate * grad_a</span><br><span class="line">    b -= learning_rate * grad_b</span><br><span class="line">    c -= learning_rate * grad_c</span><br><span class="line">    d -= learning_rate * grad_d</span><br><span class="line"></span><br><span class="line">print(f&quot;result: y = &#123;a.item()&#125; + &#123;b.item()&#125; x + &#123;c.item()&#125; x^2 + &#123;d.item()&#125; x^3&quot;)</span><br></pre></td></tr></table></figure>
<p>输出结果：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">99 1479.1622314453125</span><br><span class="line">199 1029.018310546875</span><br><span class="line">299 717.3475341796875</span><br><span class="line">399 501.3380432128906</span><br><span class="line">499 351.484130859375</span><br><span class="line">599 247.42686462402344</span><br><span class="line">699 175.10452270507812</span><br><span class="line">799 124.79450225830078</span><br><span class="line">899 89.76720428466797</span><br><span class="line">999 65.35990142822266</span><br><span class="line">1099 48.339378356933594</span><br><span class="line">1199 36.46087646484375</span><br><span class="line">1299 28.164865493774414</span><br><span class="line">1399 22.36684799194336</span><br><span class="line">1499 18.311866760253906</span><br><span class="line">1599 15.474104881286621</span><br><span class="line">1699 13.48697566986084</span><br><span class="line">1799 12.094669342041016</span><br><span class="line">1899 11.11857795715332</span><br><span class="line">1999 10.433902740478516</span><br><span class="line">result: y = -0.040275223553180695 + 0.8441053628921509 x + 0.006948145106434822 x^2 + -0.0915331020951271 x^3</span><br></pre></td></tr></table></figure>
<p>其中：torch.linspace(start, end, steps, *, out&#x3D;None, dtype&#x3D;None, layout&#x3D;torch.strided, device&#x3D;None, requires_grad&#x3D;False) → Tensor返回一个一维的tensor(张量)，这个张量包含了从start到end（包括端点）的等距的steps个数据点。例：print(torch.linspace(3,10,5))   输出结果为tensor([ 3.0000, 4.7500, 6.5000, 8.2500, 10.0000])参数：</p>
<ul>
<li>start(float) -点集的起始值；</li>
<li>end(float) -点集的结束值；</li>
<li>steps(int) - 分割的点数，默认是100；</li>
<li>out (Tensor, optional) - 结果张量；</li>
<li>dtype：返回值（张量）的数据类型。</li>
</ul>
<p>torch.randn()，返回一个符合均值为0，方差为1的正态分布（标准正态分布）中填充随机数的张量。</p>
<h1 id="autograd"><a href="#autograd" class="headerlink" title="autograd"></a>autograd</h1><h2 id="pytorch-tensors-and-autograd"><a href="#pytorch-tensors-and-autograd" class="headerlink" title="pytorch: tensors and autograd"></a>pytorch: tensors and autograd</h2><p>上面的例子必须手动实现神经网络的前向和反向传递。对于小型两层网络来说，手动实现反向传递并不是什么大问题，但对于大型复杂网络来说，很快就会变得非常棘手。</p>
<p>值得庆幸的是，自动微分可以自动计算神经网络中的反向传递。PyTorch 中的自动分级包正是提供此功能。使用自动分级时，网络的正向传递将定义一个计算图，图中的节点将是张量，边缘将是从输入张量生成输出张量的函数。然后，通过此图反向传播，您可以轻松计算梯度。</p>
<p>这听起来很复杂，在实践中使用起来非常简单。每个张量表示计算图中的一个节点。如果x是一个具有x.requires_grad&#x3D;True的张量，则x.grad是另一个张量，它保持 x 对某个标量值的梯度。</p>
<p>在这里，使用PyTorch张量和自动渐变来实现拟合正弦波与三阶多项式示例；现在不再需要手动实现通过网络的向后传递。</p>
<h2 id="PyTorch-定义新的-autograd-函数"><a href="#PyTorch-定义新的-autograd-函数" class="headerlink" title="PyTorch: 定义新的 autograd 函数"></a>PyTorch: 定义新的 autograd 函数</h2><p>在底层，每个原始的 autograd 运算符实际上是两个对张量进行操作的函数。正向函数从输入张量计算输出张量。向后函数接收输出张量相对于某个标量值的梯度，并计算输入张量相对于同一标量值的梯度。</p>
<p>在 PyTorch 中，通过定义一个子类torch.autograd.Function和实现前向及反向传播函数很容易定义 autograd 运算符。之后，可以通过使用新的 autograd 运算符，通过构造一个实例并像函数一样调用它，传递包含输入数据的张量。</p>
<p>在此示例中，将模型定义为代替,其中是三次勒让德多项式。本文编写了自己的自定义 Autograd 函数来计算P[3]的前进和后退，并使用它来实现该模型。</p>
<h1 id="nn-model"><a href="#nn-model" class="headerlink" title="nn model"></a>nn model</h1><h2 id="PyTorch-nn"><a href="#PyTorch-nn" class="headerlink" title="PyTorch: nn"></a>PyTorch: nn</h2><p>在 PyTorch 中，nn包定义了一组模块，它们大致等效于神经网络层。 模块接收输入张量并计算输出张量，但也可以保持内部状态，例如包含可学习参数的张量。 nn包还定义了一组有用的损失函数，这些函数通常在训练神经网络时使用。</p>
<p>在此示例中，使用nn包来实现多项式模型网络：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line">import math</span><br><span class="line"></span><br><span class="line">#创建张量来保存输入和输出</span><br><span class="line">x = torch.linspace(-math.pi,math.pi,2000)    #linspace:序列生成器，在给定区间内以均匀步长生成数字序列</span><br><span class="line">y = torch.sin(x)</span><br><span class="line"></span><br><span class="line">#这个例子中，输出y是关于x, x^2, x^3的线性函数，所以可以把它看作是一个线性神经网络，准备张量tensor(x, x^2, x^3)</span><br><span class="line">p = torch.tensor([1,2,3])</span><br><span class="line">xx = x.unsqueeze(-1).pow(p)</span><br><span class="line"></span><br><span class="line">#在上面代码中，x.unsqueeze(-1) 有 shape (2000, 1)， p 有 shape(3,)；</span><br><span class="line">#对于这个代码，广播语义将应用到获取形状为shape (2000, 3)的一个张量.</span><br><span class="line"></span><br><span class="line">#使用 nn 包将模型定义为一个层序列;</span><br><span class="line">#nn.Sequential是一个包含其他模块的模块，按顺序应用它们以产生其输出;</span><br><span class="line">#线性模块的输出是通过输入的线性函数来计算的，并保存内部张量的权重和偏差;</span><br><span class="line">#Flatten 层将线性层的输出展平为一维张量去匹配y的形状.</span><br><span class="line"></span><br><span class="line">model = torch.nn.Sequential(</span><br><span class="line">    torch.nn.Linear(3,1),</span><br><span class="line">    torch.nn.Flatten(0,1)    #Flatten(0,1):降维，把多维转换成一维</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">#nn也包含流行的定义好的损失函数，在这个示例中，将使用Mean Squared Error (MSE)损失函数.</span><br><span class="line">loss_fn = torch.nn.MSELoss(reduction=&#x27;sum&#x27;)   #sum是对结果矩阵各个元素求和</span><br><span class="line">learning_rate = 1e-6</span><br><span class="line">for t in range(2000):</span><br><span class="line">    #前向传播：通过将 x 传递给模型来计算预测的 y.</span><br><span class="line">    # 覆盖 __call__ 操作符，这样就可以像函数一样调用它们.</span><br><span class="line">    #这样做时，将输入数据的张量传递给模块，它会产生输出数据的张量.</span><br><span class="line">    y_pred = model(xx)</span><br><span class="line"></span><br><span class="line">    #计算并打印loss，传递的张量包含y的预测值和真实值，损失函数返回一个包含损失的张量.</span><br><span class="line">    loss = loss_fn(y_pred,y)</span><br><span class="line">    if t % 100 == 99:</span><br><span class="line">        print(t,loss.item())</span><br><span class="line"></span><br><span class="line">    #在运行反向传递之前将梯度归零.</span><br><span class="line">    model.zero_grad()</span><br><span class="line"></span><br><span class="line">    #后向传递：计算模型所有可学习参数的损失梯度.</span><br><span class="line">    #在内部，每个模块的参数都存储在 requires_grad=True 的张量中，因此此调用将计算模型中所有可学习参数的梯度.</span><br><span class="line">    loss.backward()</span><br><span class="line"></span><br><span class="line">    #使用梯度下降更新权重。每个参数都是一个张量，所以可以像以前一样访问它的梯度.</span><br><span class="line">    with torch.no_grad():</span><br><span class="line">        for param in model.parameters():</span><br><span class="line">            param -= learning_rate * param.grad</span><br><span class="line"></span><br><span class="line">#您可以访问“model”的第一层，就像访问列表的第一项.</span><br><span class="line">linear_layer = model[0]</span><br><span class="line"></span><br><span class="line">#对于线性层，其参数存储为“权重”和“偏差”.</span><br><span class="line">print(f&#x27;result: y = &#123;linear_layer.bias.item()&#125; + &#123;linear_layer.weight[:, 0].item()&#125; x + &#x27;</span><br><span class="line">      f&#x27;&#123;linear_layer.weight[:,1].item()&#125; x^2 + &#123;linear_layer.weight[:,2].item()&#125; x^3&#x27;)</span><br></pre></td></tr></table></figure>
<p>输出结果：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">99 1043.3065185546875</span><br><span class="line">199 692.8822021484375</span><br><span class="line">299 461.1615295410156</span><br><span class="line">399 307.93426513671875</span><br><span class="line">499 206.61143493652344</span><br><span class="line">599 139.6107635498047</span><br><span class="line">699 95.30604553222656</span><br><span class="line">799 66.00914001464844</span><br><span class="line">899 46.63624572753906</span><br><span class="line">999 33.82560348510742</span><br><span class="line">1099 25.354406356811523</span><br><span class="line">1199 19.75271987915039</span><br><span class="line">1299 16.048513412475586</span><br><span class="line">1399 13.599020957946777</span><br><span class="line">1499 11.979267120361328</span><br><span class="line">1599 10.908172607421875</span><br><span class="line">1699 10.199882507324219</span><br><span class="line">1799 9.731518745422363</span><br><span class="line">1899 9.421815872192383</span><br><span class="line">1999 9.217001914978027</span><br><span class="line">result: y = 0.0005339012132026255 + 0.8373093008995056 x + -9.210744610754773e-05 x^2 + -0.09056641906499863 x^3</span><br></pre></td></tr></table></figure>


<h2 id="PyTorch-optim"><a href="#PyTorch-optim" class="headerlink" title="PyTorch: optim"></a>PyTorch: optim</h2><p>到目前为止，通过使用torch.no_grad()手动更改持有可学习参数的张量来更新模型的权重。 对于像随机梯度下降这样的简单优化算法来说，这并不是一个巨大的负担，但是在实践中，经常使用更复杂的优化器（例如 AdaGrad，RMSProp，Adam 等）来训练神经网络。PyTorch 中的optim包抽象了优化算法的思想，并提供了常用优化算法的实现。在此示例中，将使用nn包像以前一样定义我们的模型，但是我们将使用optim包提供的 RMSprop 算法来优化模型：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line">import math</span><br><span class="line"></span><br><span class="line">x = torch.linspace(-math.pi, math.pi, 2000)</span><br><span class="line">y = torch.sin(x)</span><br><span class="line"></span><br><span class="line">p = torch.tensor([1, 2, 3])</span><br><span class="line">xx = x.unsqueeze(-1).pow(p)</span><br><span class="line"></span><br><span class="line">model = torch.nn.Sequential(</span><br><span class="line">    torch.nn.Linear(3, 1),</span><br><span class="line">    torch.nn.Flatten(0, 1)</span><br><span class="line">)</span><br><span class="line">loss_fn = torch.nn.MSELoss(reduction=&#x27;sum&#x27;)</span><br><span class="line"></span><br><span class="line">learning_rate = 1e-3</span><br><span class="line">optimizer = torch.optim.RMSprop(model.parameters(), lr=learning_rate)</span><br><span class="line">for t in range(2000):</span><br><span class="line">    y_pred = model(xx)</span><br><span class="line"></span><br><span class="line">    loss = loss_fn(y_pred, y)</span><br><span class="line">    if t % 100 == 99:</span><br><span class="line">        print(t, loss.item())</span><br><span class="line"></span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line">    loss.backward()</span><br><span class="line">    optimizer.step()</span><br><span class="line"></span><br><span class="line">linear_layer = model[0]</span><br><span class="line">print(f&#x27;Result: y = &#123;linear_layer.bias.item()&#125; + &#123;linear_layer.weight[:, 0].item()&#125; x + &#x27;</span><br><span class="line">      f&#x27;&#123;linear_layer.weight[:, 1].item()&#125; x^2 + &#123;linear_layer.weight[:, 2].item()&#125; x^3&#x27;)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>输出结果：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">99 4199.068359375</span><br><span class="line">199 1251.85888671875</span><br><span class="line">299 744.5487060546875</span><br><span class="line">399 650.283447265625</span><br><span class="line">499 568.83349609375</span><br><span class="line">599 476.1234436035156</span><br><span class="line">699 378.39129638671875</span><br><span class="line">799 285.1864013671875</span><br><span class="line">899 203.7239990234375</span><br><span class="line">999 137.22006225585938</span><br><span class="line">1099 86.24774932861328</span><br><span class="line">1199 50.04513168334961</span><br><span class="line">1299 27.013656616210938</span><br><span class="line">1399 14.817473411560059</span><br><span class="line">1499 10.082954406738281</span><br><span class="line">1599 9.017213821411133</span><br><span class="line">1699 9.001590728759766</span><br><span class="line">1799 8.925690650939941</span><br><span class="line">1899 8.897751808166504</span><br><span class="line">1999 8.914302825927734</span><br><span class="line">Result: y = 0.0004996994393877685 + 0.8562811613082886 x + 0.0004997377400286496 x^2 + -0.0938219279050827 x^3</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<h2 id="PyTorch-自定义-nn-模块"><a href="#PyTorch-自定义-nn-模块" class="headerlink" title="PyTorch: 自定义 nn 模块"></a>PyTorch: 自定义 nn 模块</h2><p>有时，您将需要指定比一系列现有模块更复杂的模型。 对于这些情况，您可以通过子类化nn.Module并定义一个forward来定义自己的模块，该模块使用其他模块或在 Tensors 上的其他自动转换操作来接收输入 Tensors 并生成输出 Tensors。</p>
<p>在此示例中，我们将三阶多项式实现为自定义Module子类：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line">import math</span><br><span class="line"></span><br><span class="line">class Polynomial3(torch.nn.Module):</span><br><span class="line">    def __init__(self):</span><br><span class="line">        #在构造函数中，我们实例化了四个参数并将它们分配为成员参数</span><br><span class="line">        super().__init__()</span><br><span class="line">        self.a = torch.nn.Parameter(torch.randn(()))</span><br><span class="line">        self.b = torch.nn.Parameter(torch.randn(()))</span><br><span class="line">        self.c = torch.nn.Parameter(torch.randn(()))</span><br><span class="line">        self.d = torch.nn.Parameter(torch.randn(()))</span><br><span class="line"></span><br><span class="line">    def forward(self,x):</span><br><span class="line">        #在forward函数中，接受输入数据的张量，必须返回输出数据的张量。</span><br><span class="line">        # 可以使用构造函数中定义的模块以及张量上的任意运算符</span><br><span class="line">        return self.a + self.b * x + self.c * x ** 2 + self.d * x ** 3</span><br><span class="line"></span><br><span class="line">    def string(self):</span><br><span class="line">        #与 Python 中的任何类一样，也可以在 PyTorch 模块上定义自定义方法</span><br><span class="line">        return f&#x27;y = &#123;self.a.item()&#125; + &#123;self.b.item()&#125; x +&#123;self.c.item()&#125; x^2 + &#123;self.d.item()&#125; x^3&#x27;</span><br><span class="line"></span><br><span class="line">x = torch.linspace(-math.pi,math.pi,2000)</span><br><span class="line">y = torch.sin(x)</span><br><span class="line"></span><br><span class="line">#通过实例化上面定义的类来构建模型</span><br><span class="line">model = Polynomial3()</span><br><span class="line"></span><br><span class="line">#构建损失函数和优化器.SGD 构造函数中对 model.parameters() 的调用将包含模型成员 nn.Linear 模块的可学习参数。</span><br><span class="line">criterion = torch.nn.MSELoss(reduction=&#x27;sum&#x27;)    #均方损失函数loss(x,y)=(x-y)^2</span><br><span class="line">optimizer = torch.optim.SGD(model.parameters(),lr=1e-6)</span><br><span class="line">for t in range(2000):</span><br><span class="line">    #向前传递：把x传给模型，计算出预测y</span><br><span class="line">    y_pred = model(x)</span><br><span class="line"></span><br><span class="line">    #计算、打印loss</span><br><span class="line">    loss = criterion(y_pred,y)</span><br><span class="line">    if t % 100 == 99:</span><br><span class="line">        print(t,loss.item())</span><br><span class="line"></span><br><span class="line">    #梯度置零，执行向后传递，更新权重</span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line">    loss.backward()</span><br><span class="line">    optimizer.step()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">print(f&#x27;result: &#123;model.string()&#125;&#x27;)</span><br></pre></td></tr></table></figure>
<p>输出结果：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">99 1355.4447021484375</span><br><span class="line">199 900.5872802734375</span><br><span class="line">299 599.42919921875</span><br><span class="line">399 400.0167541503906</span><br><span class="line">499 267.9629211425781</span><br><span class="line">599 180.5065155029297</span><br><span class="line">699 122.57975006103516</span><br><span class="line">799 84.20748138427734</span><br><span class="line">899 58.78575897216797</span><br><span class="line">999 41.94147491455078</span><br><span class="line">1099 30.77896499633789</span><br><span class="line">1199 23.38070297241211</span><br><span class="line">1299 18.476526260375977</span><br><span class="line">1399 15.225118637084961</span><br><span class="line">1499 13.069113731384277</span><br><span class="line">1599 11.639115333557129</span><br><span class="line">1699 10.690498352050781</span><br><span class="line">1799 10.06110954284668</span><br><span class="line">1899 9.643372535705566</span><br><span class="line">1999 9.36609935760498</span><br><span class="line">result: y = -0.0066633448004722595 + 0.83480304479599 x +0.0011495368089526892 x^2 + -0.09020992368459702 x^3</span><br></pre></td></tr></table></figure>


<h2 id="PyTorch控制流-权重共享"><a href="#PyTorch控制流-权重共享" class="headerlink" title="PyTorch控制流+权重共享"></a>PyTorch控制流+权重共享</h2><p>作为动态图和权重分配的一个例子，我们实现了一个非常奇怪的模型: 一个三五阶多项式在每次正向传播时选择一个介于3和5之间的随机数，并使用该阶数，重复使用相同的权重多次计算第四和第五阶。</p>
<p>对于此模型，我们可以使用常规的 Python 流控制来实现循环，并且可以通过在定义正向传播时简单地多次重复使用相同的参数来实现权重共享。</p>
<p>我们可以轻松地将此模型实现为Module子类：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">import random</span><br><span class="line">import torch</span><br><span class="line">import math</span><br><span class="line"></span><br><span class="line">class DynamicNet(torch.nn.Module):</span><br><span class="line">    def __init__(self):</span><br><span class="line">        super().__init__()</span><br><span class="line">        self.a = torch.nn.Parameter(torch.randn(()))</span><br><span class="line">        self.b = torch.nn.Parameter(torch.randn(()))</span><br><span class="line">        self.c = torch.nn.Parameter(torch.randn(()))</span><br><span class="line">        self.d = torch.nn.Parameter(torch.randn(()))</span><br><span class="line">        self.e = torch.nn.Parameter(torch.randn(()))</span><br><span class="line"></span><br><span class="line">    def forward(self,x):</span><br><span class="line">        y = self.a + self.b * x +self.c * x ** 2 +self.d * x ** 3</span><br><span class="line">        for exp in range(4,random.randint(4,6)):</span><br><span class="line">            y = y + self.e * x ** exp</span><br><span class="line">        return y</span><br><span class="line"></span><br><span class="line">    def string(self):</span><br><span class="line">        return f&#x27;y = &#123;self.a.item()&#125; + &#123;self.b.item()&#125; x + &#123;self.c.item()&#125; x ^2 + &#123;self.d.item()&#125; x*3&#x27; \</span><br><span class="line">               f&#x27;&#123;self.e.item()&#125; x^4 ? + &#123;self.e.item()&#125; x^5 ?&#x27;</span><br><span class="line"></span><br><span class="line">x = torch.linspace(-math.pi,math.pi,2000)</span><br><span class="line">y = torch.sin(x)</span><br><span class="line"></span><br><span class="line">model = DynamicNet()</span><br><span class="line">criterion = torch.nn.MSELoss(reduction=&#x27;sum&#x27;)</span><br><span class="line">optimizer = torch.optim.SGD(model.parameters(),lr=1e-8,momentum=0.9)</span><br><span class="line"></span><br><span class="line">for t in range(30000):</span><br><span class="line">    y_pred = model(x)</span><br><span class="line">    loss = criterion(y_pred,y)</span><br><span class="line">    if t % 2000 == 1999:</span><br><span class="line">        print(t,loss.item())</span><br><span class="line"></span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line">    loss.backward()</span><br><span class="line">    optimizer.step()</span><br><span class="line"></span><br><span class="line">print(f&#x27;result:&#123;model.string()&#125;&#x27;)</span><br></pre></td></tr></table></figure>
<p>输出结果：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">1999 1868.185546875</span><br><span class="line">3999 901.3772583007812</span><br><span class="line">5999 471.8838806152344</span><br><span class="line">7999 242.06170654296875</span><br><span class="line">9999 133.9963836669922</span><br><span class="line">11999 131.37423706054688</span><br><span class="line">13999 38.36183166503906</span><br><span class="line">15999 23.234813690185547</span><br><span class="line">17999 16.192235946655273</span><br><span class="line">19999 12.5375394821167</span><br><span class="line">21999 10.831731796264648</span><br><span class="line">23999 9.643186569213867</span><br><span class="line">25999 9.118908882141113</span><br><span class="line">27999 9.150856018066406</span><br><span class="line">29999 9.009603500366211</span><br><span class="line">result:y = -0.011092226952314377 + 0.8570550084114075 x + 0.0014420193620026112 x ^2 + -0.09358233213424683 x*30.00010753657988971099 x^4 ? + 0.00010753657988971099 x^5 ?</span><br></pre></td></tr></table></figure>


    </div>

    
    
    
        <div class="reward-container">
  <div></div>
  <button onclick="var qr = document.getElementById('qr'); qr.style.display = (qr.style.display === 'none') ? 'block' : 'none';">
    打赏
  </button>
  <div id="qr" style="display: none;">
      
      <div style="display: inline-block;">
        <img src="/images/wechatpay.png" alt="SindreYang 微信支付">
        <p>微信支付</p>
      </div>
      
      <div style="display: inline-block;">
        <img src="/images/alipay.png" alt="SindreYang 支付宝">
        <p>支付宝</p>
      </div>

  </div>
</div>

        

<div>
<ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>本文作者： </strong>SindreYang
  </li>
  <li class="post-copyright-link">
    <strong>本文链接：</strong>
    <a href="http://blog.mviai.com/2025/1._%E7%86%9F%E6%82%89pytorch_----__2_pytorch%E7%A4%BA%E4%BE%8B/" title="1">http://blog.mviai.com/2025/1._熟悉pytorch_----__2_pytorch示例/</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <span class="exturl" data-url="aHR0cHM6Ly9jcmVhdGl2ZWNvbW1vbnMub3JnL2xpY2Vuc2VzL2J5LW5jLXNhLzQuMC9kZWVkLnpo"><i class="fa fa-fw fa-creative-commons"></i>BY-NC-SA</span> 许可协议。转载请注明出处！
  </li>
</ul>
</div>

        

  <div class="followme">
    <p>欢迎关注我的其它发布渠道</p>

    <div class="social-list">

        <div class="social-item">
          <a target="_blank" class="social-link" href="/images/wechat.png">
            <span class="icon">
              <i class="fa fa-wechat"></i>
            </span>

            <span class="label">WeChat</span>
          </a>
        </div>
    </div>
  </div>


      <footer class="post-footer">

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2025/1._%E7%86%9F%E6%82%89pytorch_----__3_%E5%9B%BE%E5%83%8F/" rel="prev" title="1">
      <i class="fa fa-chevron-left"></i> 1
    </a></div>
      <div class="post-nav-item">
    <a href="/2025/1._%E7%86%9F%E6%82%89pytorch_----__1_%E7%AE%80%E4%BB%8B/" rel="next" title="1">
      1 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          
    
  <div class="comments">
    <div id="SOHUCS"></div>
  </div>
  

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Tensors"><span class="nav-number">1.</span> <span class="nav-text">Tensors</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Warm-up-numpy"><span class="nav-number">1.1.</span> <span class="nav-text">Warm-up: numpy</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Pytorch-Tensors"><span class="nav-number">1.2.</span> <span class="nav-text">Pytorch:Tensors</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#autograd"><span class="nav-number">2.</span> <span class="nav-text">autograd</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#pytorch-tensors-and-autograd"><span class="nav-number">2.1.</span> <span class="nav-text">pytorch: tensors and autograd</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#PyTorch-%E5%AE%9A%E4%B9%89%E6%96%B0%E7%9A%84-autograd-%E5%87%BD%E6%95%B0"><span class="nav-number">2.2.</span> <span class="nav-text">PyTorch: 定义新的 autograd 函数</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#nn-model"><span class="nav-number">3.</span> <span class="nav-text">nn model</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#PyTorch-nn"><span class="nav-number">3.1.</span> <span class="nav-text">PyTorch: nn</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#PyTorch-optim"><span class="nav-number">3.2.</span> <span class="nav-text">PyTorch: optim</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#PyTorch-%E8%87%AA%E5%AE%9A%E4%B9%89-nn-%E6%A8%A1%E5%9D%97"><span class="nav-number">3.3.</span> <span class="nav-text">PyTorch: 自定义 nn 模块</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#PyTorch%E6%8E%A7%E5%88%B6%E6%B5%81-%E6%9D%83%E9%87%8D%E5%85%B1%E4%BA%AB"><span class="nav-number">3.4.</span> <span class="nav-text">PyTorch控制流+权重共享</span></a></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="SindreYang"
      src="/images/avatar.png">
  <p class="site-author-name" itemprop="name">SindreYang</p>
  <div class="site-description" itemprop="description">沉淀后我愿意做一个温暖的人。有自己的喜好，有自己的原则，有自己的信仰，不急功近利，不浮夸轻薄，宠辱不惊，淡定安逸，心静如水。------不忘初心，方得始终</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">321</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">72</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL1NpbmRyZVlhbmc=" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;SindreYang"><i class="fa fa-fw fa-github"></i>GitHub</span>
      </span>
      <span class="links-of-author-item">
        <span class="exturl" data-url="bWFpbHRvOnl4QG12aWFpLmNvbQ==" title="E-Mail → mailto:yx@mviai.com"><i class="fa fa-fw fa-envelope"></i>E-Mail</span>
      </span>
  </div>
  <div class="cc-license motion-element" itemprop="license">
    <span class="exturl cc-opacity" data-url="aHR0cHM6Ly9jcmVhdGl2ZWNvbW1vbnMub3JnL2xpY2Vuc2VzL2J5LW5jLXNhLzQuMC9kZWVkLnpo"><img src="/images/cc-by-nc-sa.svg" alt="Creative Commons"></span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        
  <div class="languages">
    <label class="lang-select-label">
      <i class="fa fa-language"></i>
      <span>简体中文</span>
      <i class="fa fa-angle-up" aria-hidden="true"></i>
    </label>
    <select class="lang-select" data-canonical="">
      
        <option value="zh-CN" data-href="/2025/1._%E7%86%9F%E6%82%89pytorch_----__2_pytorch%E7%A4%BA%E4%BE%8B/" selected="">
          简体中文
        </option>
      
        <option value="en" data-href="/en/2025/1._%E7%86%9F%E6%82%89pytorch_----__2_pytorch%E7%A4%BA%E4%BE%8B/" selected="">
          English
        </option>
      
    </select>
  </div>

        

<div class="copyright">
  
  &copy; 2018 – 
  <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">SindreYang</span>
</div><!-- 页面点击小红心 -->
<script type="text/javascript" src="/js/love.js"></script>
<!-- 背景波浪 -->
<script color="0,0,255" opacity="0.5" zIndex="-1" count="99" src="https://cdn.jsdelivr.net/npm/canvas-nest.js@1/dist/canvas-nest.js"></script>


<!-- 腾讯企业邮箱 -->
<style>
.bizmail_loginpanel {
    font-size: 12px;
    width: 300px;
    height: auto;
    background: transparent;
    margin-left: auto;
    margin-right: auto;
}

.bizmail_LoginBox {
    padding: 10px 15px;
}


.bizmail_loginpanel form {
    margin: 0;
    padding: 0;
}

.bizmail_loginpanel input.text {
    font-size: 12px;
    width: 100px;
    height: 20px;
    margin: 0 2px;
    background-color: transparent;
    border:1px solid transparent;
    box-shadow: none;
    color: black;
}

.bizmail_loginpanel .bizmail_column {
    height: 28px;
}

.bizmail_loginpanel .bizmail_column label {
    display: block;
    float: left;
    width: 30px;
    height: 24px;
    line-height: 24px;
    font-size: 12px;
}

.bizmail_loginpanel .bizmail_column .bizmail_inputArea {
    float: left;
    width: 240px;
}

.bizmail_loginpanel .bizmail_column span {
    font-size: 12px;
    word-wrap: break-word;
    margin-left: 2px;
    line-height: 200%;
}

.bizmail_loginpanel .bizmail_SubmitArea {
    margin-left: 30px;
    clear: both;
}

.bizmail_loginpanel .bizmail_SubmitArea a {
    font-size: 12px;
    margin-left: 5px;
}

.bizmail_loginpanel select {
    width: 110px;
    height: 20px;
    margin: 0 2px;
}
.bizmail_loginpanel input {

    background-color: rgba(83, 126, 236, 0.562);
}


</style>

<script type="text/javascript">
function checkInput() {
    var e = document.form1.uin,
        i = document.form1.pwd;
    return 0 == e.value.length ? e.focus() : 0 == i.value.length ? i.focus() : (document.form1.submit(), setTimeout(" document.form1.pwd.value = '' ", 500)), !1
}

function writeLoginPanel(e) {
    if (e && e.domainlist && -1 != e.domainlist.indexOf(".")) {
        var a = "return checkInput()",
            t = '<div id="divLoginpanelHor" class="bizmail_loginpanel" style="width:550px;"><div class="bizmail_LoginBox"><form name="form1" action="https://exmail.qq.com/cgi-bin/login" target="_blank" method="post" onsubmit="' + a + '"><input type="hidden" name="firstlogin" value="false" /><input type="hidden" name="errtemplate" value="dm_loginpage" /><input type="hidden" name="aliastype" value="other" /><input type="hidden" name="dmtype" value="bizmail" /><input type="hidden" name="p" value="" /><label>\u8d26\u53f7:</label><input type="text" name="uin" class="text" value="" />@#domainlist#<label>&nbsp&nbsp&nbsp;\u5bc6\u7801:</label><input type="password" name="pwd" class="text" value="" /><input type="submit" class="" name="" value="\u767b\u5f55" />&nbsp;<a href="https://exmail.qq.com/cgi-bin/readtemplate?check=false&t=biz_rf_portal#recovery" target="_blank">\u5fd8\u8bb0\u5bc6\u7801\uff1f</a></form></div></div>',
            n = '<div id="divLoginpanelVer" class="bizmail_loginpanel"><div class="bizmail_LoginBox"><form name="form1" action="https://exmail.qq.com/cgi-bin/login" target="_blank" method="post" onsubmit="' + a + '"><input type="hidden" name="firstlogin" value="false" /><input type="hidden" name="errtemplate" value="dm_loginpage" /><input type="hidden" name="aliastype" value="other" /><input type="hidden" name="dmtype" value="bizmail" /><input type="hidden" name="p" value="" /><div class="bizmail_column"><label>\u8d26\u53f7:</label><div class="bizmail_inputArea"><input type="text" name="uin" class="text" value="" />@#domainlist#</div></div><div class="bizmail_column"><label>\u5bc6\u7801:</label><div class="bizmail_inputArea"><input type="password" name="pwd" class="text" value="" /></div></div><div class="bizmail_SubmitArea"><input type="submit" class="" name="" style="width:66px;" value="\u767b\u5f55" /><a href="https://exmail.qq.com/cgi-bin/readtemplate?check=false&t=biz_rf_portal#recovery" target="_blank">\u5fd8\u8bb0\u5bc6\u7801\uff1f</a></div></form></div></div>',
            l = e.domainlist.split(";");
        if (1 == l.length) var m = '<span>#domain#</span><input type="hidden" name="domain" value="#domain#" />'.replace(/#domain#/g, l[0]);
        else {
            m = '<select name="domain">';
            for (i = 0; i < l.length; i++) m += '<option value="' + l[i] + '">' + l[i] + "</option>";
            m += "</select>"
        }
        e.mode && "vertical" != e.mode && "both" != e.mode || document.write(n.replace(/#domainlist#/g, m)), "horizontal" != e.mode && "both" != e.mode || document.write(t.replace(/#domainlist#/g, m))
    }
}

</script>      

<script type="text/javascript"> writeLoginPanel({domainlist:"mviai.com", mode:"horizontal"});</script>      


        








      </div>
    </footer>
  </div>

  
  <script size="300" alpha="0.6" zIndex="-1" src="/lib/canvas-ribbon/canvas-ribbon.js"></script>
  <script src="/lib/anime.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/medium-zoom@1/dist/medium-zoom.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>


  <script defer src="/lib/three/three.min.js"></script>
    <script defer src="/lib/three/three-waves.min.js"></script>


  




  
<script src="/js/local-search.js"></script>









<script>
document.querySelectorAll('.pdfobject-container').forEach(element => {
  let url = element.dataset.target;
  let pdfOpenParams = {
    navpanes : 0,
    toolbar  : 0,
    statusbar: 0,
    pagemode : 'thumbs',
    view     : 'FitH'
  };
  let pdfOpenFragment = '#' + Object.entries(pdfOpenParams).map(([key, value]) => `${key}=${encodeURIComponent(value)}`).join('&');
  let fullURL = `/lib/pdf/web/viewer.html?file=${encodeURIComponent(url)}${pdfOpenFragment}`;

  if (NexT.utils.supportsPDFs()) {
    element.innerHTML = `<embed class="pdfobject" src="${url + pdfOpenFragment}" type="application/pdf" style="height: ${element.dataset.height};">`;
  } else {
    element.innerHTML = `<iframe src="${fullURL}" style="height: ${element.dataset.height};" frameborder="0"></iframe>`;
  }
});
</script>




  

  

  <script>
  NexT.utils.loadComments(document.querySelector('#SOHUCS'), () => {
    var appid = 'cyxmItxjS';
    var conf = 'e5e71132d9086bb54aeeba6e88e87df9';
    var width = window.innerWidth || document.documentElement.clientWidth;
    if (width < 960) {
      window.document.write('<script id="changyan_mobile_js" charset="utf-8" type="text/javascript" src="https://cy-cdn.kuaizhan.com/upload/mobile/wap-js/changyan_mobile.js?client_id=' + appid + '&conf=' + conf + '"><\/script>');
    } else {
      var loadJs=function(d,a){var c=document.getElementsByTagName("head")[0]||document.head||document.documentElement;var b=document.createElement("script");b.setAttribute("type","text/javascript");b.setAttribute("charset","UTF-8");b.setAttribute("src",d);if(typeof a==="function"){if(window.attachEvent){b.onreadystatechange=function(){var e=b.readyState;if(e==="loaded"||e==="complete"){b.onreadystatechange=null;a()}}}else{b.onload=a}}c.appendChild(b)};loadJs("https://changyan.sohu.com/upload/changyan.js",function(){window.changyan.api.config({appid:appid,conf:conf})});
    }
  });
  </script>
  <script src="https://cy-cdn.kuaizhan.com/upload/plugins/plugins.count.js"></script>

<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"jsonPath":"/live2dw/assets/z16.model.json"},"display":{"position":"left","width":75,"height":150},"mobile":{"show":true},"log":false});</script></body>
</html>




