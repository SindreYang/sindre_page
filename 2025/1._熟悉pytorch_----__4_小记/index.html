<!DOCTYPE html>
<html lang="zh-CN,en,default">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 7.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">
  <link rel="stylesheet" href="/lib/pace/pace-theme-minimal.min.css">
  <script src="/lib/pace/pace.min.js"></script>

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"blog.mviai.com","root":"/","scheme":"Gemini","version":"7.8.0","exturl":true,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":true,"style":"mac"},"back2top":{"enable":true,"sidebar":false,"scrollpercent":true},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":true,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="自动摘要: 	torch.eye()	torch.eye(n,m&#x3D;None,*,out&#x3D;None,dtype&#x3D;None,layout&#x3D;torch.strided,device&#x3D;None,requ ……..">
<meta property="og:type" content="article">
<meta property="og:title" content="1">
<meta property="og:url" content="http://blog.mviai.com/2025/1._%E7%86%9F%E6%82%89pytorch_----__4_%E5%B0%8F%E8%AE%B0/index.html">
<meta property="og:site_name" content="落叶无痕">
<meta property="og:description" content="自动摘要: 	torch.eye()	torch.eye(n,m&#x3D;None,*,out&#x3D;None,dtype&#x3D;None,layout&#x3D;torch.strided,device&#x3D;None,requ ……..">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://blog.mviai.com/images/2c639706f6237262ca14cc1209e6731f.svg">
<meta property="og:image" content="http://blog.mviai.com/images/cc35248bd56d7742dcaa02d003429575.svg">
<meta property="og:image" content="http://blog.mviai.com/images/579946b500e4d97f74f421b2ef3c1067.svg">
<meta property="og:image" content="http://blog.mviai.com/images/e8d3a8f4bc03ecd673c5eba632689eba.svg">
<meta property="og:image" content="http://blog.mviai.com/images/1b3243c66c1f2380da41bf6d720532ca.svg">
<meta property="og:image" content="http://blog.mviai.com/images/2c639706f6237262ca14cc1209e6731f.svg">
<meta property="og:image" content="http://blog.mviai.com/images/559f02a07572f1763edae9b005a6f005.svg">
<meta property="og:image" content="http://blog.mviai.com/images/8de3aea4332c18e414592b8d6a246c5e.svg">
<meta property="og:image" content="http://blog.mviai.com/images/20faaf3f49751ca74b91695739aa6cc6.svg">
<meta property="og:image" content="http://blog.mviai.com/images/2c639706f6237262ca14cc1209e6731f.svg">
<meta property="og:image" content="http://blog.mviai.com/images/2c639706f6237262ca14cc1209e6731f.svg">
<meta property="og:image" content="http://blog.mviai.com/images/559f02a07572f1763edae9b005a6f005.svg">
<meta property="og:image" content="http://blog.mviai.com/images/cc35248bd56d7742dcaa02d003429575.svg">
<meta property="og:image" content="http://blog.mviai.com/images/cc35248bd56d7742dcaa02d003429575.svg">
<meta property="og:image" content="http://blog.mviai.com/images/579946b500e4d97f74f421b2ef3c1067.svg">
<meta property="og:image" content="http://blog.mviai.com/images/f5aba32c8291d3029a1157a1141dd271.svg">
<meta property="og:image" content="http://blog.mviai.com/images/87d97fc8df977505e2dc281465675134.svg">
<meta property="og:image" content="http://blog.mviai.com/images/23cc5c44888224a50c6817f101fd0297.svg">
<meta property="og:image" content="http://blog.mviai.com/images/2e81afa715151a24494554c2610e1b0a.svg">
<meta property="og:image" content="http://blog.mviai.com/images/2e81afa715151a24494554c2610e1b0a.svg">
<meta property="og:image" content="http://blog.mviai.com/images/e8d3a8f4bc03ecd673c5eba632689eba.svg">
<meta property="og:image" content="http://blog.mviai.com/images/9ad0aaf57eb07dd549c34cc93735e975.svg">
<meta property="og:image" content="http://blog.mviai.com/images/2c639706f6237262ca14cc1209e6731f.svg">
<meta property="og:image" content="http://blog.mviai.com/images/559f02a07572f1763edae9b005a6f005.svg">
<meta property="og:image" content="http://blog.mviai.com/images/8de3aea4332c18e414592b8d6a246c5e.svg">
<meta property="og:image" content="http://blog.mviai.com/images/20faaf3f49751ca74b91695739aa6cc6.svg">
<meta property="og:image" content="http://blog.mviai.com/images/3c7c152c6dd0fd97a701fced2615dd00.svg">
<meta property="og:image" content="http://blog.mviai.com/images/3212ef7118dc1f97df0ebc50c8a608ba.svg">
<meta property="og:image" content="http://blog.mviai.com/images/817d26ccd211529396b6ad1484fd83cb.svg">
<meta property="og:image" content="http://blog.mviai.com/images/77f8ef2b072125de3af6f826b1322f3e.svg">
<meta property="og:image" content="http://blog.mviai.com/images/4dfb1f8581316f004eeb1611535ff5ce.svg">
<meta property="og:image" content="http://blog.mviai.com/images/6a5ecc586eb31301b2d20a32daed7dd7.svg">
<meta property="og:image" content="http://blog.mviai.com/images/23cc5c44888224a50c6817f101fd0297.svg">
<meta property="og:image" content="http://blog.mviai.com/images/38602c5493c353c4746b2853fb6c5563.svg">
<meta property="og:image" content="http://blog.mviai.com/images/23cc5c44888224a50c6817f101fd0297.svg">
<meta property="og:image" content="http://blog.mviai.com/images/38602c5493c353c4746b2853fb6c5563.svg">
<meta property="og:image" content="http://blog.mviai.com/images/e3d2a6a29407cde88112b96c23a6bc61.svg">
<meta property="og:image" content="http://blog.mviai.com/images/716131870440232348b1503d3279d4fe.svg">
<meta property="og:image" content="http://blog.mviai.com/images/716131870440232348b1503d3279d4fe.svg">
<meta property="og:image" content="http://blog.mviai.com/images/23c5750858ae585a0ee1827b96a647fb.svg">
<meta property="og:image" content="http://blog.mviai.com/images/23c5750858ae585a0ee1827b96a647fb.svg">
<meta property="og:image" content="http://blog.mviai.com/images/23cc5c44888224a50c6817f101fd0297.svg">
<meta property="og:image" content="http://blog.mviai.com/images/9a6f11fe88eeb0cca08732b51ac626d0.svg">
<meta property="og:image" content="http://blog.mviai.com/images/ff69f4220314dced44d4102b9ee6010c.svg">
<meta property="og:image" content="http://blog.mviai.com/images/b7e458e1293a8abbdd54da46b9920ca9.svg">
<meta property="og:image" content="http://blog.mviai.com/images/7f3fd5a0349b038d6fe0c0fa74684915.svg">
<meta property="og:image" content="http://blog.mviai.com/images/a168c186746cf188813456fd4db4dd70.svg">
<meta property="og:image" content="http://blog.mviai.com/images/850bd1b327f93e790fc649ebf2a7e60e.svg">
<meta property="og:image" content="http://blog.mviai.com/images/b7e458e1293a8abbdd54da46b9920ca9.svg">
<meta property="og:image" content="http://blog.mviai.com/images/7f3fd5a0349b038d6fe0c0fa74684915.svg">
<meta property="og:image" content="http://blog.mviai.com/images/a168c186746cf188813456fd4db4dd70.svg">
<meta property="og:image" content="http://blog.mviai.com/images/1b96a81123c6c5b53e3145aa85e88e37.svg">
<meta property="article:published_time" content="2025-01-22T04:37:41.000Z">
<meta property="article:modified_time" content="2025-01-22T12:37:41.667Z">
<meta property="article:author" content="SindreYang">
<meta property="article:tag" content="生活">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://blog.mviai.com/images/2c639706f6237262ca14cc1209e6731f.svg">

<link rel="canonical" href="http://blog.mviai.com/2025/1._%E7%86%9F%E6%82%89pytorch_----__4_%E5%B0%8F%E8%AE%B0/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>1 | 落叶无痕</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">落叶无痕</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>首页</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-fw fa-user"></i>关于</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i>分类<span class="badge">72</span></a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>归档<span class="badge">321</span></a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>

  <span class="exturl github-corner" data-url="aHR0cHM6Ly9naXRodWIuY29tL1NpbmRyZVlhbmc=" title="Follow me on GitHub" aria-label="Follow me on GitHub"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></span>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://blog.mviai.com/2025/1._%E7%86%9F%E6%82%89pytorch_----__4_%E5%B0%8F%E8%AE%B0/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="SindreYang">
      <meta itemprop="description" content="沉淀后我愿意做一个温暖的人。有自己的喜好，有自己的原则，有自己的信仰，不急功近利，不浮夸轻薄，宠辱不惊，淡定安逸，心静如水。------不忘初心，方得始终">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="落叶无痕">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          1
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2025-01-22 12:37:41 / 修改时间：20:37:41" itemprop="dateCreated datePublished" datetime="2025-01-22T12:37:41+08:00">2025-01-22</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%88%86%E5%89%B2%E5%9F%B9%E8%AE%AD%E8%AE%A1%E5%88%92/" itemprop="url" rel="index"><span itemprop="name">分割培训计划</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="fa fa-comment-o"></i>
      </span>
      <span class="post-meta-item-text">Changyan：</span>
    
    
      <a title="changyan" href="/2025/1._%E7%86%9F%E6%82%89pytorch_----__4_%E5%B0%8F%E8%AE%B0/#SOHUCS" itemprop="discussionUrl">
        <span id="changyan_count_unit" class="post-comments-count hc-comment-count" data-xid="2025/1._熟悉pytorch_----__4_小记/" itemprop="commentCount"></span>
      </a>
    
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>自动摘要: 	torch.eye()	torch.eye(n,m&#x3D;None,*,out&#x3D;None,dtype&#x3D;None,layout&#x3D;torch.strided,device&#x3D;None,requ ……..</p>
<span id="more"></span>

<h1 id="torch-eye"><a href="#torch-eye" class="headerlink" title="torch.eye()"></a>torch.eye()</h1><p>torch.eye(n, m&#x3D;None, *, out&#x3D;None, dtype&#x3D;None, layout&#x3D;torch.strided, device&#x3D;None, requires_grad&#x3D;False) → Tensor<strong>返回值</strong>：一个二维张量，对角线上有 1，其他地方有零<strong>返回类型</strong>：tensor<strong>参数</strong>：</p>
<ul>
<li>n(int) - 行数</li>
<li>m(int, optional) - 可选参数，列数，默认值为n</li>
</ul>
<p>关键词参数：optional –&gt; 可选参数</p>
<ul>
<li>out (Tensor, optional) – 输出张量</li>
<li>dtype (torch.dtype, optional) – 返回张量的数据类型。默认值: 如果无，则使用全局默认值</li>
<li>layout (torch.layout, optional) – 返回张量的期望布局。默认值: torch.strided</li>
<li>device(torch.device, optional) – 返回张量所需的装置(CPU or CUDA)。默认值: 如果没有，则使用当前设备的默认张量类型(参见 torch.set _ Default _ tensor _ type ())。设备将 CPU 为 CPU 张量类型和当前 CUDA 设备为 CUDA 张量类型。</li>
<li>requires_grad (bool, optional) – 如果 autograd 应该记录返回张量的操作。默认：False</li>
</ul>
<p>例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.eye(<span class="number">3</span>)</span><br></pre></td></tr></table></figure>
<p>输出结果：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tensor([[ <span class="number">1.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>],</span><br><span class="line">        [ <span class="number">0.</span>,  <span class="number">1.</span>,  <span class="number">0.</span>],</span><br><span class="line">        [ <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">1.</span>]])</span><br></pre></td></tr></table></figure>



<h1 id="torch-eq"><a href="#torch-eq" class="headerlink" title="torch.eq"></a>torch.eq</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.eq(<span class="built_in">input</span>, other, *, out=<span class="literal">None</span>) → Tensor</span><br></pre></td></tr></table></figure>
<p>计算元素相等第二个参数可以是一个数字或张量，其形状与第一个参数一起是可广播的。</p>
<p>参数：input (Tensor) – 要比较的张量；other (Tensor or float) – 要比较的张量或值；</p>
<p>关键字参数：out (Tensor, optional) – 输出张量。</p>
<p>返回值：一个布尔张量，为 True，input等于 other，否则为 False。</p>
<p>示例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.eq(torch.tensor([[<span class="number">1</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">4</span>]]), torch.tensor([[<span class="number">1</span>, <span class="number">1</span>], [<span class="number">4</span>, <span class="number">4</span>]]))</span><br></pre></td></tr></table></figure>
<p>输出结果：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tensor([[ <span class="literal">True</span>, <span class="literal">False</span>],</span><br><span class="line">        [<span class="literal">False</span>, <span class="literal">True</span>]])</span><br></pre></td></tr></table></figure>



<h1 id="torch-nn-Conv1d"><a href="#torch-nn-Conv1d" class="headerlink" title="torch.nn.Conv1d"></a>torch.nn.Conv1d</h1><p>CLASS torch.nn.Conv1d(in_channels, out_channels, kernel_size, stride&#x3D;1, padding&#x3D;0, dilation&#x3D;1, groups&#x3D;1, bias&#x3D;True, padding_mode&#x3D;’zeros’, device&#x3D;None, dtype&#x3D;None)</p>
<p>在由几个输入平面组成的输入信号上应用一维卷积。</p>
<p>在最简单的情况下，输入大小为(N,<img src="/images/2c639706f6237262ca14cc1209e6731f.svg"><br>,L)的层的输出值(N,<img src="/images/cc35248bd56d7742dcaa02d003429575.svg"><br>,<img src="/images/579946b500e4d97f74f421b2ef3c1067.svg"><br>)可以精确地描述为:<img src="/images/e8d3a8f4bc03ecd673c5eba632689eba.svg"><br>其中，*是矩阵乘法， N为批量大小(每次输入数据的个数)， C为通道数(特征数)，L代表序列的长度(最内维度的长度)。</p>
<p>此模块支持 TensorFloat32。在某些 ROCm 显卡设备上，当使用 float16输入时，该模块将使用不同的向后精度。</p>
<ul>
<li>stride：控制互相关、单个数字或一个元素元组的步长(卷积步长)。</li>
<li>padding：控制应用于输入的填充量。它可以是一个字符串{‘ valid’, ‘same’} ，也可以是一个整数元组，给出两边应用的隐式填充量。</li>
<li>dilation：控制卷积核元素之间的间距; 也称为多孔算法。这很难描述，但是这个链接可以很好地显示dilation的作用。</li>
<li>groups：控制输入和输出之间的连接。 in _ channel 和 out _ channel 都必须被组整除。例如：<ul>
<li>当 groups &#x3D; 1时，所有的输入都卷积到所有的输出；</li>
<li>当 groups &#x3D; 2时，操作变得相当于有两个并排的 conv 层，每个层看到一半的输入通道，产生一半的输出通道，并随后连接；</li>
<li>在 groups &#x3D; in _ channel 时，每个输入通道都与自己的一组过滤器相关联(<img src="/images/1b3243c66c1f2380da41bf6d720532ca.svg"><br>)。</li>
</ul>
</li>
</ul>
<p>NOTE:</p>
<ul>
<li>当 group &#x3D; &#x3D; in _ channel 和 out _ channel &#x3D; &#x3D; K * in _ channel 时，其中 K 是一个正整数，这个操作也称为“纵向卷积”；</li>
<li>换句话说，输入一个大小为(N,<img src="/images/2c639706f6237262ca14cc1209e6731f.svg"><br>, <img src="/images/559f02a07572f1763edae9b005a6f005.svg"><br>)，可以使用这些参数执行带有纵向乘子 K 的纵向卷积(<img src="/images/8de3aea4332c18e414592b8d6a246c5e.svg"><br>, <img src="/images/20faaf3f49751ca74b91695739aa6cc6.svg"><br>)。</li>
</ul>
<p>NOTE:</p>
<ul>
<li>在某些情况下，当 CUDA 设备上给定张量并使用 CuDNN 时，该算子可以选择一种不确定算法来提高性能。如果不希望这样，可以通过设置 torch.backends.cudnn.deterministic &#x3D; True 使操作具有确定性(可能以性能开销为代价)。有关更多信息，请参见<span class="exturl" data-url="aHR0cHM6Ly9weXRvcmNoLm9yZy9kb2NzL3N0YWJsZS9ub3Rlcy9yYW5kb21uZXNzLmh0bWw=" title="https://pytorch.org/docs/stable/notes/randomness.html">重复性<i class="fa fa-external-link"></i></span>。</li>
</ul>
<p>NOTE:</p>
<ul>
<li>Padding &#x3D; ‘valid’ 与 no padding 是相同的。Pding &#x3D; ‘same’ 填充输入，以便输出具有作为输入的形状。但是，此模式不支持除1以外的任何步长值。</li>
</ul>
<p>NOTE:</p>
<ul>
<li>这个模块支持复杂的数据类型，例如: complex32, complex64, complex128.</li>
</ul>
<p>参数：</p>
<ul>
<li>in_channels (int) – 输入图像数量的渠道(一般为特征数)；</li>
<li>out_channels (int) – 卷积产生的通道数；</li>
<li>kernel_size (int or tuple) – 卷积内核的大小，卷积核的大小为(k,)，第二个维度是由in_channels来决定的，所以实际上卷积大小为kernel_size*in_channels；</li>
<li>stride (int or tuple, optional) – 卷积的步长，默认：1；</li>
<li>padding (int, tuple or str, optional) – 添加到输入两侧的填充层数，默认：0；</li>
<li>padding_mode (str, optional) – ‘zeros’, ‘reflect’, ‘replicate’ or ‘circular’. 默认： ‘zeros’；</li>
<li>dilation (int or tuple, optional) – 卷积核元素之间的间距，默认：1；</li>
<li>groups (int, optional) – 从输入通道到输出通道的阻塞连接数，默认：1；</li>
<li>bias (bool, optional) – 如果为 True，则在输出中添加一个可学习的偏置，默认：True。</li>
</ul>
<p>Shape:</p>
<ul>
<li>Input: (N,<img src="/images/2c639706f6237262ca14cc1209e6731f.svg"><br>, <img src="/images/2c639706f6237262ca14cc1209e6731f.svg"><br>, <img src="/images/559f02a07572f1763edae9b005a6f005.svg"><br>)；</li>
<li>Output: (N,<img src="/images/cc35248bd56d7742dcaa02d003429575.svg"><br>,<img src="/images/cc35248bd56d7742dcaa02d003429575.svg"><br>,<img src="/images/579946b500e4d97f74f421b2ef3c1067.svg"><br>) ，其中</li>
</ul>
<p><img src="/images/f5aba32c8291d3029a1157a1141dd271.svg"><br>。</p>
<p>变量：</p>
<ul>
<li>weight (Tensor) – shape模块可学习权重 (out_channels，<img src="/images/87d97fc8df977505e2dc281465675134.svg"><br>，kernel_size) ，这些权重的值是从<img src="/images/23cc5c44888224a50c6817f101fd0297.svg"><br>，其中<img src="/images/2e81afa715151a24494554c2610e1b0a.svg"><br>；</li>
<li>bias (Tensor) – shape模块的可学习偏差 (out_channels)。如果bias 为 True，然后这些权重的值来自<img src="/images/2e81afa715151a24494554c2610e1b0a.svg"><br>。</li>
</ul>
<p>示例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">m = nn.Conv1d(<span class="number">16</span>, <span class="number">33</span>, <span class="number">3</span>, stride=<span class="number">2</span>)</span><br><span class="line"><span class="built_in">input</span> = torch.randn(<span class="number">20</span>, <span class="number">16</span>, <span class="number">50</span>)</span><br><span class="line">output = m(<span class="built_in">input</span>)</span><br></pre></td></tr></table></figure>



<h1 id="torch-nn-Conv2d"><a href="#torch-nn-Conv2d" class="headerlink" title="torch.nn.Conv2d"></a>torch.nn.Conv2d</h1><p>CLASS torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride&#x3D;1, padding&#x3D;0, dilation&#x3D;1, groups&#x3D;1, bias&#x3D;True, padding_mode&#x3D;’zeros’, device&#x3D;None, dtype&#x3D;None)</p>
<p>在由几个输入平面组成的输入信号上应用二维卷积。</p>
<p>在最简单的情况下，输入大小为(<img src="/images/e8d3a8f4bc03ecd673c5eba632689eba.svg"><br>其中 * 是有效的二维互相关运算符，N 是批量大小，C 表示通道数，H 是以像素为单位的输入平面的高度，W 是以像素为单位的宽度。</p>
<p>此模块支持 TensorFloat32。</p>
<p>在某些 ROCm 设备上，当使用 float16输入时，该模块将使用不同的向后精度。</p>
<ul>
<li>Stride 控制互相关、单个数字或元组的步长。</li>
<li>padding：控制应用于输入的填充量。它可以是一个字符串{‘ valid’，‘ same’} ，也可以是一个整数元组，给出两边应用的隐式填充量。</li>
<li>dilation控制卷积核元素之间的间距; 也称为多孔算法。这很难描述，但是这个链接可以很好地显示dilation的作用。</li>
<li>group 控制输入和输出之间的连接. in _ channel 和 out _ channel 都必须被 groups整除, 例如,<ul>
<li>在groups &#x3D; 1时，卷积的输入数 &#x3D; 输出数。</li>
<li>在groups &#x3D; 2时，操作变得相当于有两个并排的 conv 层，每个层看到一半的输入通道，产生一半的输出通道，并随后连接。</li>
<li>在 group &#x3D; in _ channels 时，每个输入通道都有自己的过滤器组(of size <img src="/images/9ad0aaf57eb07dd549c34cc93735e975.svg"><br>)。</li>
</ul>
</li>
</ul>
<p>Kernel _ size、 stride、 pding、 dilation 参数可以是:</p>
<ul>
<li>单个 int - 在这种情况下，高度和宽度维度使用相同的值；</li>
<li>两个整数的tuple - 在这种情况下，第一个整数用于高度维度，第二个整数用于宽度维度。</li>
</ul>
<p>注意：</p>
<ul>
<li>当 group &#x3D; &#x3D; in _ channel 和 out _ channel &#x3D; &#x3D; K * in _ channel 时，其中 K 是一个正整数，这个操作也称为“纵向卷积”。</li>
<li>换句话说，输入一个大小为(N,<img src="/images/2c639706f6237262ca14cc1209e6731f.svg"><br>, <img src="/images/559f02a07572f1763edae9b005a6f005.svg"><br>)，可以使用这些参数执行带有纵向乘子 K 的纵向卷积(<img src="/images/8de3aea4332c18e414592b8d6a246c5e.svg"><br>, <img src="/images/20faaf3f49751ca74b91695739aa6cc6.svg"><br>)</li>
</ul>
<p>注意：</p>
<ul>
<li>在某些情况下，当 CUDA 设备上给定张量并使用 CuDNN 时，该算子可以选择一种不确定算法来提高性能。如果不希望这样，可以通过设置 torch.backends.cudnn.deterministic &#x3D; True 使操作具有确定性(可能以性能开销为代价)。有关更多信息，请参见<span class="exturl" data-url="aHR0cHM6Ly9weXRvcmNoLm9yZy9kb2NzL3N0YWJsZS9ub3Rlcy9yYW5kb21uZXNzLmh0bWw=" title="https://pytorch.org/docs/stable/notes/randomness.html">Reproducibility<i class="fa fa-external-link"></i></span>。</li>
</ul>
<p>注意：</p>
<ul>
<li>Padding &#x3D; ‘ valid’ 与 no padding 是相同的。Padding &#x3D; ‘same’ 将填充输入，以便输出具有作为输入的形状。但是，此模式不支持除1以外的任何步长值。</li>
</ul>
<p>注意：</p>
<ul>
<li>这个模块支持复杂的数据类型，例如: 错综复杂的数据类型32，错综复杂的数据类型64，错综复杂的数据类型128。</li>
</ul>
<p>参数：</p>
<ul>
<li>In _ channel (int) - 输入图像的通道数；</li>
<li>out _ channel (int) - 卷积产生的通道数；</li>
<li>Kernel _ Size (int 或 tuple) - 卷积内核的大小；</li>
<li>Stride (int 或 tuple，可选) - 卷积的步长。默认值: 1；</li>
<li>padding(int、 tuple 或 str，可选) - 将填充添加到输入的所有四边。默认值: 0；</li>
<li>padding _ mode (str，可选) -‘ zeros’，‘ response’，‘ copy’或‘ circulal’。默认值: ‘ zeros’；</li>
<li>dilation (int 或 tuple，可选) - 内核元素之间的间距。默认值: 1；</li>
<li>group (int，可选) - 从输入通道到输出通道的阻塞连接数；</li>
<li>bias(bool，可选) - 如果为True，则在输出中添加一个可学习的偏见。默认值：True。</li>
</ul>
<p>Shape：输入：(<img src="/images/3c7c152c6dd0fd97a701fced2615dd00.svg"><br>) or (<img src="/images/3212ef7118dc1f97df0ebc50c8a608ba.svg"><br>)输出：<img src="/images/817d26ccd211529396b6ad1484fd83cb.svg"><br> or <img src="/images/77f8ef2b072125de3af6f826b1322f3e.svg"><br>，其中<img src="/images/4dfb1f8581316f004eeb1611535ff5ce.svg"><br><img src="/images/6a5ecc586eb31301b2d20a32daed7dd7.svg"></p>
<p>变量：</p>
<ul>
<li>weight (Tensor) – 模型可学习权重的形状(out_channels, <img src="/images/23cc5c44888224a50c6817f101fd0297.svg"><br>其中<img src="/images/38602c5493c353c4746b2853fb6c5563.svg"><br>。</li>
<li>bias (Tensor) – 形状(通道)模块的可学习偏差。如果bias为True，则这些权重的值从<img src="/images/23cc5c44888224a50c6817f101fd0297.svg"><br>其中<img src="/images/38602c5493c353c4746b2853fb6c5563.svg"><br>。</li>
</ul>
<p>示例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># With square kernels and equal stride</span></span><br><span class="line">m = nn.Conv2d(<span class="number">16</span>, <span class="number">33</span>, <span class="number">3</span>, stride=<span class="number">2</span>)</span><br><span class="line"><span class="comment"># non-square kernels and unequal stride and with padding</span></span><br><span class="line">m = nn.Conv2d(<span class="number">16</span>, <span class="number">33</span>, (<span class="number">3</span>, <span class="number">5</span>), stride=(<span class="number">2</span>, <span class="number">1</span>), padding=(<span class="number">4</span>, <span class="number">2</span>))</span><br><span class="line"><span class="comment"># non-square kernels and unequal stride and with padding and dilation</span></span><br><span class="line">m = nn.Conv2d(<span class="number">16</span>, <span class="number">33</span>, (<span class="number">3</span>, <span class="number">5</span>), stride=(<span class="number">2</span>, <span class="number">1</span>), padding=(<span class="number">4</span>, <span class="number">2</span>), dilation=(<span class="number">3</span>, <span class="number">1</span>))</span><br><span class="line"><span class="built_in">input</span> = torch.randn(<span class="number">20</span>, <span class="number">16</span>, <span class="number">50</span>, <span class="number">100</span>)</span><br><span class="line">output = m(<span class="built_in">input</span>)</span><br></pre></td></tr></table></figure>



<h1 id="torch-nn-Linear"><a href="#torch-nn-Linear" class="headerlink" title="torch.nn.Linear"></a>torch.nn.Linear</h1><p>CLASS torch.nn.Linear(in_features, out_features, bias&#x3D;True, device&#x3D;None, dtype&#x3D;None)</p>
<p>对传入的数据应用线性映射：<img src="/images/e3d2a6a29407cde88112b96c23a6bc61.svg"></p>
<p>此模块支持 TensorFloat32。</p>
<p>在某些 ROCm 设备上，当使用 float16输入时，该模块将使用不同的向后精度。</p>
<p>参数：</p>
<ul>
<li>in_features (int) – 每个输入样本的大小；</li>
<li>out_features (int) – 每个输出样本的大小；</li>
<li>bias (bool) – 如果设置为 False，图层将不会学习附加偏置。默认值: True。</li>
</ul>
<p>Shape:</p>
<ul>
<li>Input: (∗, <img src="/images/716131870440232348b1503d3279d4fe.svg"><br>)其中 * 表示任意数量的尺寸包括none，<img src="/images/716131870440232348b1503d3279d4fe.svg"><br>&#x3D;  in_features ；</li>
<li>Output: (∗, <img src="/images/23c5750858ae585a0ee1827b96a647fb.svg"><br>)除了最后一个维度外，其他所有维度的形状都与输入相同，<img src="/images/23c5750858ae585a0ee1827b96a647fb.svg"><br>&#x3D; out_features 。</li>
</ul>
<p>变量：weight (torch.Tensor) – 模块的可学的权重的形状(out_features, in_features)。初始化值<img src="/images/23cc5c44888224a50c6817f101fd0297.svg"><br>，其中<img src="/images/9a6f11fe88eeb0cca08732b51ac626d0.svg"></p>
<p>示例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">m = nn.Linear(<span class="number">20</span>, <span class="number">30</span>)</span><br><span class="line"><span class="built_in">input</span> = torch.randn(<span class="number">128</span>, <span class="number">20</span>)</span><br><span class="line">output = m(<span class="built_in">input</span>)</span><br><span class="line"><span class="built_in">print</span>(output.size())</span><br></pre></td></tr></table></figure>
<p>输出结果：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.Size([<span class="number">128</span>, <span class="number">30</span>])</span><br></pre></td></tr></table></figure>



<h1 id="torch-nn-BatchNorm1d"><a href="#torch-nn-BatchNorm1d" class="headerlink" title="torch.nn.BatchNorm1d"></a>torch.nn.BatchNorm1d</h1><p>CLASS torch.nn.BatchNorm1d(num_features, eps&#x3D;1e-05, momentum&#x3D;0.1, affine&#x3D;True, track_running_stats&#x3D;True, device&#x3D;None, dtype&#x3D;None)</p>
<p>在2D 或3D 输入上应用批量标准化，如文中所述的批量标准化: 通过减少内部协变量移位加速深度网络训练。<img src="/images/ff69f4220314dced44d4102b9ee6010c.svg"><br>平均值和标准偏差是在小批量上每维计算的，γ 和  β 是大小为 C 的可学习参数向量(其中 C 是输入的特征或通道的数目)。默认情况下，γ 的元素被设置为1，而 β 的元素被设置为 0 。标准偏差是通过有偏估计器计算的，等效于 torch.var (input, unbiased &#x3D; False)。</p>
<p>默认情况下，在训练期间，这一层保持运行其计算出的平均值和方差的估计值，然后在评估期间使用这些估计值进行归一化。运行估计保持默认 momentum 为0.1。</p>
<p>如果 track _ running _ stats 被设置为 False，那么这个层就不会保留运行估计值，而是在评估期间使用批量统计信息。</p>
<p>NOTE:这个momentum参数不同于优化器类中使用的动量参数和传统的动量概念。从数学上讲，这里运行统计信息的更新规则是<img src="/images/b7e458e1293a8abbdd54da46b9920ca9.svg"><br>，其中<img src="/images/7f3fd5a0349b038d6fe0c0fa74684915.svg"><br>是估计的统计量和 <img src="/images/a168c186746cf188813456fd4db4dd70.svg"><br>是新的观测值。</p>
<p>因为批处理标准化是在 C 维度上完成的，在(N，L)切片上计算统计信息，所以常用的术语称之为时态批处理标准化。</p>
<p>参数：</p>
<ul>
<li>num_features (int) – 输入的特征数或通道数C；</li>
<li>eps (float) – 数值稳定性分母的附加值，默认：1e-5；</li>
<li>momentum (float) – 用于 running _ mean 和 running _ var 计算的值。累积移动平均数(即简单平均数)可设定为None。默认：0.1；</li>
<li>affine (bool) – 一个布尔值，当设置为 True 时，该模块具有可学习的仿射参数。默认：True；</li>
<li>track_running_stats (bool) – 一个布尔值，当设置为 True 时，该模块跟踪正在运行的均值和方差，当设置为 False 时，该模块不跟踪这样的统计信息，并将统计缓冲区 running _ mean 和 running _ var 初始化为 Nothing。当这些缓冲区为 Nothing 时，此模块始终使用批处理统计信息。在训练和评估两种模式下。默认：True。</li>
</ul>
<p>Shape:</p>
<ul>
<li>Input: (N，C)或(N，C，L)，其中 N 是批量大小，C 是特征或通道的数目，L 是序列长度；</li>
<li>Output: (N, C)或(N，C，L) ，与输入形状相同。</li>
</ul>
<p>示例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#有可学习的参数</span></span><br><span class="line">m = nn.BatchNorm1d(<span class="number">100</span>)</span><br><span class="line"><span class="comment">#没有可学习的参数</span></span><br><span class="line">m = nn.BatchNorm1d(<span class="number">100</span>, affine=<span class="literal">False</span>)</span><br><span class="line"><span class="built_in">input</span> = torch.randn(<span class="number">20</span>, <span class="number">100</span>)</span><br><span class="line">output = m(<span class="built_in">input</span>)</span><br><span class="line"><span class="built_in">print</span>(output)</span><br></pre></td></tr></table></figure>



<h1 id="torch-nn-BatchNorm2d"><a href="#torch-nn-BatchNorm2d" class="headerlink" title="torch.nn.BatchNorm2d"></a>torch.nn.BatchNorm2d</h1><p>CLASS torch.nn.BatchNorm2d(num_features, eps&#x3D;1e-05, momentum&#x3D;0.1, affine&#x3D;True, track_running_stats&#x3D;True, device&#x3D;None, dtype&#x3D;None)</p>
<p>在一个4D 输入上应用批量标准化(一个附加通道尺寸的小批量2D 输入) ，正如文章中描述的批量标准化: 通过减少内部协变量移位加速深度网络训练。<img src="/images/850bd1b327f93e790fc649ebf2a7e60e.svg"><br>平均值和标准偏差是在小批量上每维计算的，γ 和 β 是大小 C (其中 C 是输入大小)的可学习的参数向量。默认情况下，将 γ 的元素设置为1，将 β 的元素设置为0。标准偏差是通过有偏估计器计算的，等效于 torch.var (input, unbiased &#x3D; False)。</p>
<p>默认情况下，在训练期间，这一层保持运行其计算出的平均值和方差的估计值，然后在评估期间使用这些估计值进行归一化。运行估计保持默认 momentum为0.1。</p>
<p>如果 track _ running _ stats 被设置为 False，那么这个层就不会保留运行估计值，而是在评估期间使用批量统计信息。</p>
<p>NOTE:这个 momentum 参数不同于优化器类中使用的动量参数和传统的动量概念。从数学上讲，这里运行统计信息的更新规则是<img src="/images/b7e458e1293a8abbdd54da46b9920ca9.svg"><br>，其中<img src="/images/7f3fd5a0349b038d6fe0c0fa74684915.svg"><br>是估计的统计量和 <img src="/images/a168c186746cf188813456fd4db4dd70.svg"><br>是新的观测值。</p>
<p>因为批量标准化是在 C 维度上完成的，在(N，H，W)切片上计算统计信息，所以常用的术语称之为空间批量标准化。</p>
<p>参数：</p>
<ul>
<li>num_features (int) – C 来源于期望输入的大小(N，C，H，W)；</li>
<li>eps (float) – 增加到数值稳定性分母的值。默认值: 1e-5；</li>
<li>momentum (float) – 用于 running _ mean 和 running _ var 计算的值。累积移动平均数(即简单平均数)可设定为无。默认值: 0.1；</li>
<li>affine (bool) – 一个布尔值，当设置为 True 时，该模块具有可学习的仿射参数；</li>
<li>track_running_stats (bool) – 一个布尔值，当设置为 True 时，该模块跟踪正在运行的均值和方差，当设置为 False 时，该模块不跟踪这样的统计信息，并将统计缓冲区 running _ mean 和 running _ var 初始化为 None。当这些缓冲区为 None 时，此模块始终使用批处理统计信息。在训练和评估两种模式下。默认值: True；</li>
</ul>
<p>Shape:</p>
<ul>
<li>Input: (N, C, H, W)</li>
<li>Output: (N, C, H, W) (same shape as input)</li>
</ul>
<p>示例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># With Learnable Parameters</span></span><br><span class="line">m = nn.BatchNorm2d(<span class="number">100</span>)</span><br><span class="line"><span class="comment"># Without Learnable Parameters</span></span><br><span class="line">m = nn.BatchNorm2d(<span class="number">100</span>, affine=<span class="literal">False</span>)</span><br><span class="line"><span class="built_in">input</span> = torch.randn(<span class="number">20</span>, <span class="number">100</span>, <span class="number">35</span>, <span class="number">45</span>)</span><br><span class="line">output = m(<span class="built_in">input</span>)</span><br></pre></td></tr></table></figure>



<h1 id="torch-nn-ReLU"><a href="#torch-nn-ReLU" class="headerlink" title="torch.nn.ReLU"></a>torch.nn.ReLU</h1><p>CLASS torch.nn.ReLU(inplace&#x3D;False)激活函数用于校正线性函数的权重：<img src="/images/1b96a81123c6c5b53e3145aa85e88e37.svg"></p>
<p>参数：inplace (bool) – 可以选择就地进行操作，默认：False。</p>
<p>Shape：Input: (∗)，其中 ∗ 表示任意数量的尺寸；Output: (∗), 与输入形状相同。</p>
<h1 id="torch-nn-Sequential"><a href="#torch-nn-Sequential" class="headerlink" title="torch.nn.Sequential"></a>torch.nn.Sequential</h1><p>CLASS torch.nn.Sequential(*args: Module)CLASS torch.nn.Sequential(arg: OrderedDict[str, Module])顺序容器。模块将按照它们在构造函数中传递的顺序添加到它。或者，也可以传入模块的 OrderedDect。Sequential 的 forward ()方法接受任何输入，并将其转发给它包含的第一个模块。然后，它将输出“链接”到每个后续模块的输入，最后返回最后一个模块的输出。</p>
<p>Sequential 通过手动调用模块序列提供的价值在于，它允许将整个容器视为一个单独的模块，例如，对Sequential 执行转换将应用于它存储的每个模块(每个模块都是 Sequential 的注册子模块)。</p>
<p>Sequential 和 torch.nn.ModuleList 有什么区别？ModuleList 就像它听起来的那样——一个用于存储 Modules 的列表！另一方面，在一个顺序的层是连接在一个级联的方式。</p>
<p>示例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Using Sequential to create a small model. When `model` is run,</span></span><br><span class="line"><span class="comment"># input will first be passed to `Conv2d(1,20,5)`. The output of</span></span><br><span class="line"><span class="comment"># `Conv2d(1,20,5)` will be used as the input to the first</span></span><br><span class="line"><span class="comment"># `ReLU`; the output of the first `ReLU` will become the input</span></span><br><span class="line"><span class="comment"># for `Conv2d(20,64,5)`. Finally, the output of</span></span><br><span class="line"><span class="comment"># `Conv2d(20,64,5)` will be used as input to the second `ReLU`</span></span><br><span class="line">model = nn.Sequential(</span><br><span class="line">          nn.Conv2d(<span class="number">1</span>,<span class="number">20</span>,<span class="number">5</span>),</span><br><span class="line">          nn.ReLU(),</span><br><span class="line">          nn.Conv2d(<span class="number">20</span>,<span class="number">64</span>,<span class="number">5</span>),</span><br><span class="line">          nn.ReLU()</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line"><span class="comment"># Using Sequential with OrderedDict. This is functionally the</span></span><br><span class="line"><span class="comment"># same as the above code</span></span><br><span class="line">model = nn.Sequential(OrderedDict([</span><br><span class="line">          (<span class="string">&#x27;conv1&#x27;</span>, nn.Conv2d(<span class="number">1</span>,<span class="number">20</span>,<span class="number">5</span>)),</span><br><span class="line">          (<span class="string">&#x27;relu1&#x27;</span>, nn.ReLU()),</span><br><span class="line">          (<span class="string">&#x27;conv2&#x27;</span>, nn.Conv2d(<span class="number">20</span>,<span class="number">64</span>,<span class="number">5</span>)),</span><br><span class="line">          (<span class="string">&#x27;relu2&#x27;</span>, nn.ReLU())</span><br><span class="line">        ]))</span><br></pre></td></tr></table></figure>

<p>append(module)：将给定模块追加到末尾。Parameters:module (nn.Module) – 要添加的Module。Return type:Sequential。</p>
<h1 id="torch-nn-ModuleList"><a href="#torch-nn-ModuleList" class="headerlink" title="torch.nn.ModuleList"></a>torch.nn.ModuleList</h1><p>CLASS torch.nn.ModuleList(modules&#x3D;None)</p>
<p>将子模块保存在列表中。</p>
<p>ModuleList 可以像普通 Python 列表一样进行索引，但是它包含的模块已经自动注册整个网络上，并且所有 Module 方法都可以看到它。</p>
<p>参数：modules (iterable, optional) – 添加可迭代的模块</p>
<p>示例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MyModule</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(MyModule, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        <span class="variable language_">self</span>.linears = nn.ModuleList([nn.Linear(<span class="number">10</span>, <span class="number">10</span>) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>)])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="comment"># ModuleList can act as an iterable, or be indexed using ints</span></span><br><span class="line">        <span class="keyword">for</span> i, l <span class="keyword">in</span> <span class="built_in">enumerate</span>(<span class="variable language_">self</span>.linears):</span><br><span class="line">            x = <span class="variable language_">self</span>.linears[i // <span class="number">2</span>](x) + l(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>

<p>append(module)：将给定模块追加到列表的末尾。参数：module (nn.Module) – 要追加的模块。返回类型:ModuleList</p>
<p>extend(modules)将 Python 中的模块可迭代地追加到列表的末尾。参数：modules (iterable) – 添加可迭代模块。返回类型：<span class="exturl" data-url="aHR0cHM6Ly9weXRvcmNoLm9yZy9kb2NzL3N0YWJsZS9nZW5lcmF0ZWQvdG9yY2gubm4uTW9kdWxlTGlzdC5odG1sP2hpZ2hsaWdodD1tb2R1bGVsaXN0I3RvcmNoLm5uLk1vZHVsZUxpc3Q=" title="https://pytorch.org/docs/stable/generated/torch.nn.ModuleList.html?highlight=modulelist#torch.nn.ModuleList">ModuleList<i class="fa fa-external-link"></i></span></p>
<p>insert(index, module)在列表中的给定索引前插入给定模块。参数：index (int) – 要插入的索引；module (nn.Module) – 要插入的模块。</p>
<h1 id=""><a href="#" class="headerlink" title=""></a></h1>
    </div>

    
    
    
        <div class="reward-container">
  <div></div>
  <button onclick="var qr = document.getElementById('qr'); qr.style.display = (qr.style.display === 'none') ? 'block' : 'none';">
    打赏
  </button>
  <div id="qr" style="display: none;">
      
      <div style="display: inline-block;">
        <img src="/images/wechatpay.png" alt="SindreYang 微信支付">
        <p>微信支付</p>
      </div>
      
      <div style="display: inline-block;">
        <img src="/images/alipay.png" alt="SindreYang 支付宝">
        <p>支付宝</p>
      </div>

  </div>
</div>

        

<div>
<ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>本文作者： </strong>SindreYang
  </li>
  <li class="post-copyright-link">
    <strong>本文链接：</strong>
    <a href="http://blog.mviai.com/2025/1._%E7%86%9F%E6%82%89pytorch_----__4_%E5%B0%8F%E8%AE%B0/" title="1">http://blog.mviai.com/2025/1._熟悉pytorch_----__4_小记/</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <span class="exturl" data-url="aHR0cHM6Ly9jcmVhdGl2ZWNvbW1vbnMub3JnL2xpY2Vuc2VzL2J5LW5jLXNhLzQuMC9kZWVkLnpo"><i class="fa fa-fw fa-creative-commons"></i>BY-NC-SA</span> 许可协议。转载请注明出处！
  </li>
</ul>
</div>

        

  <div class="followme">
    <p>欢迎关注我的其它发布渠道</p>

    <div class="social-list">

        <div class="social-item">
          <a target="_blank" class="social-link" href="/images/wechat.png">
            <span class="icon">
              <i class="fa fa-wechat"></i>
            </span>

            <span class="label">WeChat</span>
          </a>
        </div>
    </div>
  </div>


      <footer class="post-footer">

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2025/1._%E7%86%9F%E6%82%89%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7WebStorm/" rel="prev" title="1">
      <i class="fa fa-chevron-left"></i> 1
    </a></div>
      <div class="post-nav-item">
    <a href="/2025/1._%E7%86%9F%E6%82%89pytorch_----__3_%E5%9B%BE%E5%83%8F/" rel="next" title="1">
      1 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          
    
  <div class="comments">
    <div id="SOHUCS"></div>
  </div>
  

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#torch-eye"><span class="nav-number">1.</span> <span class="nav-text">torch.eye()</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#torch-eq"><span class="nav-number">2.</span> <span class="nav-text">torch.eq</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#torch-nn-Conv1d"><span class="nav-number">3.</span> <span class="nav-text">torch.nn.Conv1d</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#torch-nn-Conv2d"><span class="nav-number">4.</span> <span class="nav-text">torch.nn.Conv2d</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#torch-nn-Linear"><span class="nav-number">5.</span> <span class="nav-text">torch.nn.Linear</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#torch-nn-BatchNorm1d"><span class="nav-number">6.</span> <span class="nav-text">torch.nn.BatchNorm1d</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#torch-nn-BatchNorm2d"><span class="nav-number">7.</span> <span class="nav-text">torch.nn.BatchNorm2d</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#torch-nn-ReLU"><span class="nav-number">8.</span> <span class="nav-text">torch.nn.ReLU</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#torch-nn-Sequential"><span class="nav-number">9.</span> <span class="nav-text">torch.nn.Sequential</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#torch-nn-ModuleList"><span class="nav-number">10.</span> <span class="nav-text">torch.nn.ModuleList</span></a></li><li class="nav-item nav-level-1"><a class="nav-link"><span class="nav-number">11.</span> <span class="nav-text"></span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="SindreYang"
      src="/images/avatar.png">
  <p class="site-author-name" itemprop="name">SindreYang</p>
  <div class="site-description" itemprop="description">沉淀后我愿意做一个温暖的人。有自己的喜好，有自己的原则，有自己的信仰，不急功近利，不浮夸轻薄，宠辱不惊，淡定安逸，心静如水。------不忘初心，方得始终</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">321</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">72</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL1NpbmRyZVlhbmc=" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;SindreYang"><i class="fa fa-fw fa-github"></i>GitHub</span>
      </span>
      <span class="links-of-author-item">
        <span class="exturl" data-url="bWFpbHRvOnl4QG12aWFpLmNvbQ==" title="E-Mail → mailto:yx@mviai.com"><i class="fa fa-fw fa-envelope"></i>E-Mail</span>
      </span>
  </div>
  <div class="cc-license motion-element" itemprop="license">
    <span class="exturl cc-opacity" data-url="aHR0cHM6Ly9jcmVhdGl2ZWNvbW1vbnMub3JnL2xpY2Vuc2VzL2J5LW5jLXNhLzQuMC9kZWVkLnpo"><img src="/images/cc-by-nc-sa.svg" alt="Creative Commons"></span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        
  <div class="languages">
    <label class="lang-select-label">
      <i class="fa fa-language"></i>
      <span>简体中文</span>
      <i class="fa fa-angle-up" aria-hidden="true"></i>
    </label>
    <select class="lang-select" data-canonical="">
      
        <option value="zh-CN" data-href="/2025/1._%E7%86%9F%E6%82%89pytorch_----__4_%E5%B0%8F%E8%AE%B0/" selected="">
          简体中文
        </option>
      
        <option value="en" data-href="/en/2025/1._%E7%86%9F%E6%82%89pytorch_----__4_%E5%B0%8F%E8%AE%B0/" selected="">
          English
        </option>
      
    </select>
  </div>

        

<div class="copyright">
  
  &copy; 2018 – 
  <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">SindreYang</span>
</div><!-- 页面点击小红心 -->
<script type="text/javascript" src="/js/love.js"></script>
<!-- 背景波浪 -->
<script color="0,0,255" opacity="0.5" zIndex="-1" count="99" src="https://cdn.jsdelivr.net/npm/canvas-nest.js@1/dist/canvas-nest.js"></script>


<!-- 腾讯企业邮箱 -->
<style>
.bizmail_loginpanel {
    font-size: 12px;
    width: 300px;
    height: auto;
    background: transparent;
    margin-left: auto;
    margin-right: auto;
}

.bizmail_LoginBox {
    padding: 10px 15px;
}


.bizmail_loginpanel form {
    margin: 0;
    padding: 0;
}

.bizmail_loginpanel input.text {
    font-size: 12px;
    width: 100px;
    height: 20px;
    margin: 0 2px;
    background-color: transparent;
    border:1px solid transparent;
    box-shadow: none;
    color: black;
}

.bizmail_loginpanel .bizmail_column {
    height: 28px;
}

.bizmail_loginpanel .bizmail_column label {
    display: block;
    float: left;
    width: 30px;
    height: 24px;
    line-height: 24px;
    font-size: 12px;
}

.bizmail_loginpanel .bizmail_column .bizmail_inputArea {
    float: left;
    width: 240px;
}

.bizmail_loginpanel .bizmail_column span {
    font-size: 12px;
    word-wrap: break-word;
    margin-left: 2px;
    line-height: 200%;
}

.bizmail_loginpanel .bizmail_SubmitArea {
    margin-left: 30px;
    clear: both;
}

.bizmail_loginpanel .bizmail_SubmitArea a {
    font-size: 12px;
    margin-left: 5px;
}

.bizmail_loginpanel select {
    width: 110px;
    height: 20px;
    margin: 0 2px;
}
.bizmail_loginpanel input {

    background-color: rgba(83, 126, 236, 0.562);
}


</style>

<script type="text/javascript">
function checkInput() {
    var e = document.form1.uin,
        i = document.form1.pwd;
    return 0 == e.value.length ? e.focus() : 0 == i.value.length ? i.focus() : (document.form1.submit(), setTimeout(" document.form1.pwd.value = '' ", 500)), !1
}

function writeLoginPanel(e) {
    if (e && e.domainlist && -1 != e.domainlist.indexOf(".")) {
        var a = "return checkInput()",
            t = '<div id="divLoginpanelHor" class="bizmail_loginpanel" style="width:550px;"><div class="bizmail_LoginBox"><form name="form1" action="https://exmail.qq.com/cgi-bin/login" target="_blank" method="post" onsubmit="' + a + '"><input type="hidden" name="firstlogin" value="false" /><input type="hidden" name="errtemplate" value="dm_loginpage" /><input type="hidden" name="aliastype" value="other" /><input type="hidden" name="dmtype" value="bizmail" /><input type="hidden" name="p" value="" /><label>\u8d26\u53f7:</label><input type="text" name="uin" class="text" value="" />@#domainlist#<label>&nbsp&nbsp&nbsp;\u5bc6\u7801:</label><input type="password" name="pwd" class="text" value="" /><input type="submit" class="" name="" value="\u767b\u5f55" />&nbsp;<a href="https://exmail.qq.com/cgi-bin/readtemplate?check=false&t=biz_rf_portal#recovery" target="_blank">\u5fd8\u8bb0\u5bc6\u7801\uff1f</a></form></div></div>',
            n = '<div id="divLoginpanelVer" class="bizmail_loginpanel"><div class="bizmail_LoginBox"><form name="form1" action="https://exmail.qq.com/cgi-bin/login" target="_blank" method="post" onsubmit="' + a + '"><input type="hidden" name="firstlogin" value="false" /><input type="hidden" name="errtemplate" value="dm_loginpage" /><input type="hidden" name="aliastype" value="other" /><input type="hidden" name="dmtype" value="bizmail" /><input type="hidden" name="p" value="" /><div class="bizmail_column"><label>\u8d26\u53f7:</label><div class="bizmail_inputArea"><input type="text" name="uin" class="text" value="" />@#domainlist#</div></div><div class="bizmail_column"><label>\u5bc6\u7801:</label><div class="bizmail_inputArea"><input type="password" name="pwd" class="text" value="" /></div></div><div class="bizmail_SubmitArea"><input type="submit" class="" name="" style="width:66px;" value="\u767b\u5f55" /><a href="https://exmail.qq.com/cgi-bin/readtemplate?check=false&t=biz_rf_portal#recovery" target="_blank">\u5fd8\u8bb0\u5bc6\u7801\uff1f</a></div></form></div></div>',
            l = e.domainlist.split(";");
        if (1 == l.length) var m = '<span>#domain#</span><input type="hidden" name="domain" value="#domain#" />'.replace(/#domain#/g, l[0]);
        else {
            m = '<select name="domain">';
            for (i = 0; i < l.length; i++) m += '<option value="' + l[i] + '">' + l[i] + "</option>";
            m += "</select>"
        }
        e.mode && "vertical" != e.mode && "both" != e.mode || document.write(n.replace(/#domainlist#/g, m)), "horizontal" != e.mode && "both" != e.mode || document.write(t.replace(/#domainlist#/g, m))
    }
}

</script>      

<script type="text/javascript"> writeLoginPanel({domainlist:"mviai.com", mode:"horizontal"});</script>      


        








      </div>
    </footer>
  </div>

  
  <script size="300" alpha="0.6" zIndex="-1" src="/lib/canvas-ribbon/canvas-ribbon.js"></script>
  <script src="/lib/anime.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/medium-zoom@1/dist/medium-zoom.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>


  <script defer src="/lib/three/three.min.js"></script>
    <script defer src="/lib/three/three-waves.min.js"></script>


  




  
<script src="/js/local-search.js"></script>









<script>
document.querySelectorAll('.pdfobject-container').forEach(element => {
  let url = element.dataset.target;
  let pdfOpenParams = {
    navpanes : 0,
    toolbar  : 0,
    statusbar: 0,
    pagemode : 'thumbs',
    view     : 'FitH'
  };
  let pdfOpenFragment = '#' + Object.entries(pdfOpenParams).map(([key, value]) => `${key}=${encodeURIComponent(value)}`).join('&');
  let fullURL = `/lib/pdf/web/viewer.html?file=${encodeURIComponent(url)}${pdfOpenFragment}`;

  if (NexT.utils.supportsPDFs()) {
    element.innerHTML = `<embed class="pdfobject" src="${url + pdfOpenFragment}" type="application/pdf" style="height: ${element.dataset.height};">`;
  } else {
    element.innerHTML = `<iframe src="${fullURL}" style="height: ${element.dataset.height};" frameborder="0"></iframe>`;
  }
});
</script>




  

  

  <script>
  NexT.utils.loadComments(document.querySelector('#SOHUCS'), () => {
    var appid = 'cyxmItxjS';
    var conf = 'e5e71132d9086bb54aeeba6e88e87df9';
    var width = window.innerWidth || document.documentElement.clientWidth;
    if (width < 960) {
      window.document.write('<script id="changyan_mobile_js" charset="utf-8" type="text/javascript" src="https://cy-cdn.kuaizhan.com/upload/mobile/wap-js/changyan_mobile.js?client_id=' + appid + '&conf=' + conf + '"><\/script>');
    } else {
      var loadJs=function(d,a){var c=document.getElementsByTagName("head")[0]||document.head||document.documentElement;var b=document.createElement("script");b.setAttribute("type","text/javascript");b.setAttribute("charset","UTF-8");b.setAttribute("src",d);if(typeof a==="function"){if(window.attachEvent){b.onreadystatechange=function(){var e=b.readyState;if(e==="loaded"||e==="complete"){b.onreadystatechange=null;a()}}}else{b.onload=a}}c.appendChild(b)};loadJs("https://changyan.sohu.com/upload/changyan.js",function(){window.changyan.api.config({appid:appid,conf:conf})});
    }
  });
  </script>
  <script src="https://cy-cdn.kuaizhan.com/upload/plugins/plugins.count.js"></script>

<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"jsonPath":"/live2dw/assets/z16.model.json"},"display":{"position":"left","width":75,"height":150},"mobile":{"show":true},"log":false});</script></body>
</html>




